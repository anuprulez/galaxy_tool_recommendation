{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e0c99cac62ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import operator\n",
    "\n",
    "import h5py\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from keras.utils import get_custom_objects\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "size_title = 18\n",
    "size_label = 14\n",
    "n_pred = 2\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as data_file:\n",
    "        data = json.loads(data_file.read())\n",
    "    return data\n",
    "\n",
    "def create_model(model_path):\n",
    "    \n",
    "    reverse_dictionary = dict((str(v), k) for k, v in dictionary.items())\n",
    "    model_weights = list()\n",
    "    weight_ctr = 0\n",
    "    while True:\n",
    "        try:\n",
    "            d_key = \"weight_\" + str(weight_ctr)\n",
    "            weights = trained_model.get(d_key).value\n",
    "            model_weights.append(weights)\n",
    "            weight_ctr += 1\n",
    "        except Exception as exception:\n",
    "            break\n",
    "    # set the model weights\n",
    "    loaded_model.set_weights(model_weights)\n",
    "    return loaded_model, dictionary, reverse_dictionary, compatibile_tools\n",
    "\n",
    "\n",
    "def verify_model(model, tool_sequence, labels, dictionary, reverse_dictionary, compatible_tools, class_weights, topk=20, max_seq_len=25):\n",
    "    tl_seq = tool_sequence.split(\",\")\n",
    "    last_tool_name = reverse_dictionary[str(tl_seq[-1])]\n",
    "    last_compatible_tools = compatible_tools[last_tool_name]\n",
    "    sample = np.zeros(max_seq_len)\n",
    "    for idx, tool_id in enumerate(tl_seq):\n",
    "        sample[idx] = int(tool_id)\n",
    "    sample_reshaped = np.reshape(sample, (1, max_seq_len))\n",
    "\n",
    "    tool_sequence_names = [reverse_dictionary[str(tool_pos)] for tool_pos in tool_sequence.split(\",\")]\n",
    "    \n",
    "    # predict next tools for a test path\n",
    "    prediction = model.predict(sample_reshaped, verbose=0)\n",
    "    \n",
    "    weight_val = list(class_weights.values())\n",
    "    weight_val = np.reshape(weight_val, (len(weight_val),))\n",
    "    \n",
    "    prediction = np.reshape(prediction, (prediction.shape[1],))\n",
    "    \n",
    "    prediction_pos = np.argsort(prediction, axis=-1)\n",
    "\n",
    "    # get topk prediction\n",
    "    topk_prediction_pos = prediction_pos[-topk:]\n",
    "    \n",
    "    topk_prediction_val = [int(prediction[pos] * 100) for pos in topk_prediction_pos]\n",
    "    \n",
    "    topk_prediction_val = [(val * 100) / np.max(topk_prediction_val) for val in topk_prediction_val]\n",
    "    \n",
    "    # read tool names using reverse dictionary\n",
    "    pred_tool_ids = [reverse_dictionary[str(tool_pos)] for tool_pos in topk_prediction_pos if tool_pos > 0]\n",
    "    actual_next_tool_ids = list(set(pred_tool_ids).intersection(set(last_compatible_tools.split(\",\"))))\n",
    "\n",
    "    pred_tool_ids_sorted = dict()\n",
    "    for (tool_pos, tool_pred_val) in zip(topk_prediction_pos, topk_prediction_val):\n",
    "        try:\n",
    "            tool_name = reverse_dictionary[str(tool_pos)]\n",
    "            if tool_name not in last_tool_name and tool_name in actual_next_tool_ids: #tool_name in actual_next_tool_ids and \n",
    "                pred_tool_ids_sorted[tool_name] = tool_pred_val\n",
    "        except:\n",
    "            continue\n",
    "    pred_tool_ids_sorted = dict(sorted(pred_tool_ids_sorted.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    \n",
    "    cls_wt = dict()\n",
    "    usg_wt = dict()\n",
    "    inv_wt = dict()\n",
    "    ids_tools = dict()\n",
    "    keys = list(pred_tool_ids_sorted.keys())\n",
    "    for k in keys:\n",
    "        try:\n",
    "            cls_wt[k] = np.round(class_weights[str(data_dict[k])], 2)\n",
    "            usg_wt[k] = np.round(usage_weights[k], 2)\n",
    "            inv_wt[k] = np.round(inverted_weights[str(data_dict[k])], 2)\n",
    "        except:\n",
    "            continue\n",
    "    print(\"Predicted tools: \\n\")\n",
    "    print(pred_tool_ids_sorted)\n",
    "    print()\n",
    "    print(\"Class weights: \\n\")\n",
    "    cls_wt = dict(sorted(cls_wt.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    print(cls_wt)\n",
    "    print()\n",
    "    print(\"Usage weights: \\n\")\n",
    "    usg_wt = dict(sorted(usg_wt.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    print(usg_wt)\n",
    "    print()\n",
    "    total_usage_wt = np.mean(list(usg_wt.values()))\n",
    "    print(\"Mean usage wt: %0.4f\" % (total_usage_wt))\n",
    "    print()\n",
    "    print(\"Inverted weights: \\n\")\n",
    "    inv_wt = dict(sorted(inv_wt.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    print(inv_wt)\n",
    "    for key in pred_tool_ids_sorted:\n",
    "        ids_tools[key] = dictionary[key]\n",
    "    print()\n",
    "    print(\"Tool ids\")\n",
    "    print(ids_tools)\n",
    "    print(\"======================================\")\n",
    "    return cls_wt, usg_wt, inv_wt, pred_tool_ids_sorted\n",
    "\n",
    "base_path = \"data/models/\"\n",
    "\n",
    "model_path = base_path + \"model_rnn_custom_loss.hdf5\"\n",
    "\n",
    "trained_model = h5py.File(model_path, 'r')\n",
    "model_config = json.loads(trained_model.get('model_config').value)\n",
    "class_weights = json.loads(trained_model.get('class_weights').value)\n",
    "    \n",
    "loaded_model = model_from_json(model_config)\n",
    "dictionary = json.loads(trained_model.get('data_dictionary').value)\n",
    "compatibile_tools = json.loads(trained_model.get('compatible_tools').value)\n",
    "best_params = json.loads(trained_model.get('best_parameters').value)\n",
    "\n",
    "model, dictionary, reverse_dictionary, compatibile_tools = create_model(model_path)\n",
    "\n",
    "print(reverse_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted tools: \n",
      "\n",
      "{'cat1': 100.0, 'Cut1': 100.0, 'datamash_transpose': 100.0, 'Paste1': 100.0, 'addValue': 100.0, 'join1': 100.0, 'tp_tail_tool': 99.0, 'Interval_Maf_Merged_Fasta2': 99.0, 'CONVERTER_bed_gff_or_vcf_to_bigwig_0': 99.0, 'Show beginning1': 99.0, 'trimmer': 99.0, 'vegan_rarefaction': 99.0, 'hgv_david': 99.0, 'Convert characters1': 99.0, 'Fetch Taxonomic Ranks': 99.0, 'venn_list': 99.0, 'mergeCols1': 99.0, 'gops_join_1': 99.0, 'deeptools_compute_matrix': 99.0, 'Grouping1': 99.0, 'join_files_on_column_fuzzy': 99.0, 'featurecounts': 99.0, 'Summary_Statistics1': 99.0, 'random_lines1': 99.0, 'tabular_to_fastq': 99.0, 'collection_column_join': 99.0, 'datamash_ops': 99.0, 'Count1': 99.0, 'wc_gnu': 99.0, 'bedtools_coveragebed': 99.0}\n",
      "\n",
      "Class weights: \n",
      "\n",
      "{}\n",
      "\n",
      "Usage weights: \n",
      "\n",
      "{}\n",
      "\n",
      "Mean usage wt: nan\n",
      "\n",
      "Inverted weights: \n",
      "\n",
      "{}\n",
      "\n",
      "Tool ids\n",
      "{'cat1': 1258, 'Cut1': 135, 'datamash_transpose': 1071, 'Paste1': 954, 'addValue': 44, 'join1': 1262, 'tp_tail_tool': 886, 'Interval_Maf_Merged_Fasta2': 947, 'CONVERTER_bed_gff_or_vcf_to_bigwig_0': 1066, 'Show beginning1': 576, 'trimmer': 414, 'vegan_rarefaction': 1030, 'hgv_david': 466, 'Convert characters1': 586, 'Fetch Taxonomic Ranks': 465, 'venn_list': 101, 'mergeCols1': 73, 'gops_join_1': 769, 'deeptools_compute_matrix': 1241, 'Grouping1': 1018, 'join_files_on_column_fuzzy': 383, 'featurecounts': 615, 'Summary_Statistics1': 708, 'random_lines1': 146, 'tabular_to_fastq': 583, 'collection_column_join': 831, 'datamash_ops': 159, 'Count1': 559, 'wc_gnu': 930, 'bedtools_coveragebed': 403}\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({},\n",
       " {},\n",
       " {},\n",
       " {'cat1': 100.0,\n",
       "  'Cut1': 100.0,\n",
       "  'datamash_transpose': 100.0,\n",
       "  'Paste1': 100.0,\n",
       "  'addValue': 100.0,\n",
       "  'join1': 100.0,\n",
       "  'tp_tail_tool': 99.0,\n",
       "  'Interval_Maf_Merged_Fasta2': 99.0,\n",
       "  'CONVERTER_bed_gff_or_vcf_to_bigwig_0': 99.0,\n",
       "  'Show beginning1': 99.0,\n",
       "  'trimmer': 99.0,\n",
       "  'vegan_rarefaction': 99.0,\n",
       "  'hgv_david': 99.0,\n",
       "  'Convert characters1': 99.0,\n",
       "  'Fetch Taxonomic Ranks': 99.0,\n",
       "  'venn_list': 99.0,\n",
       "  'mergeCols1': 99.0,\n",
       "  'gops_join_1': 99.0,\n",
       "  'deeptools_compute_matrix': 99.0,\n",
       "  'Grouping1': 99.0,\n",
       "  'join_files_on_column_fuzzy': 99.0,\n",
       "  'featurecounts': 99.0,\n",
       "  'Summary_Statistics1': 99.0,\n",
       "  'random_lines1': 99.0,\n",
       "  'tabular_to_fastq': 99.0,\n",
       "  'collection_column_join': 99.0,\n",
       "  'datamash_ops': 99.0,\n",
       "  'Count1': 99.0,\n",
       "  'wc_gnu': 99.0,\n",
       "  'bedtools_coveragebed': 99.0})"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = 30\n",
    "tool_seq = \"605\"\n",
    "verify_model(model, tool_seq, \"\", dictionary, reverse_dictionary, compatibile_tools, class_weights, topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.927592911295817"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights[\"666\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
