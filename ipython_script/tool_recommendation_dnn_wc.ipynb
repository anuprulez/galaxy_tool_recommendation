{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool recommendation \n",
    "## (Dense neural network with weighted cross-entropy loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/kumara/miniconda3/envs/tool_prediction_cnn_wc/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kumara/miniconda3/envs/tool_prediction_cnn_wc/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kumara/miniconda3/envs/tool_prediction_cnn_wc/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kumara/miniconda3/envs/tool_prediction_cnn_wc/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kumara/miniconda3/envs/tool_prediction_cnn_wc/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kumara/miniconda3/envs/tool_prediction_cnn_wc/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import operator\n",
    "\n",
    "import h5py\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as data_file:\n",
    "        data = json.loads(data_file.read())\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_model(model_path):\n",
    "    reverse_dictionary = dict((str(v), k) for k, v in dictionary.items())\n",
    "    model_weights = list()\n",
    "    weight_ctr = 0\n",
    "    for index, item in enumerate(trained_model.keys()):\n",
    "        if \"weight_\" in item:\n",
    "            d_key = \"weight_\" + str(weight_ctr)\n",
    "            weights = trained_model.get(d_key).value\n",
    "            model_weights.append(weights)\n",
    "            weight_ctr += 1\n",
    "    # set the model weights\n",
    "    loaded_model.set_weights(model_weights)\n",
    "    return loaded_model, dictionary, reverse_dictionary\n",
    "\n",
    "def get_predicted_tools(base_tools, predictions, topk):\n",
    "    \"\"\"\n",
    "    Get predicted tools. If predicted tools are less in number, combine them with published tools\n",
    "    \"\"\"\n",
    "    intersection = list(set(predictions).intersection(set(base_tools)))\n",
    "    print(intersection)\n",
    "    print()\n",
    "    return intersection[:topk]\n",
    "\n",
    "def sort_by_usage(t_list, class_weights, d_dict):\n",
    "    \"\"\"\n",
    "    Sort predictions by usage/class weights\n",
    "    \"\"\"\n",
    "    tool_dict = dict()\n",
    "    for tool in t_list:\n",
    "        t_id = d_dict[tool]\n",
    "        tool_dict[tool] = class_weights[str(t_id)]\n",
    "    tool_dict = dict(sorted(tool_dict.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    return list(tool_dict.keys()), list(tool_dict.values())\n",
    "\n",
    "def separate_predictions(base_tools, predictions, last_tool_name, weight_values, topk):\n",
    "    \"\"\"\n",
    "    Get predictions from published and normal workflows\n",
    "    \"\"\"\n",
    "    last_base_tools = list()\n",
    "    predictions = predictions * weight_values\n",
    "    prediction_pos = np.argsort(predictions, axis=-1)\n",
    "    topk_prediction_pos = prediction_pos[-topk:]\n",
    "    # get tool ids\n",
    "    pred_tool_ids = [reverse_dictionary[str(tool_pos)] for tool_pos in topk_prediction_pos]\n",
    "    if last_tool_name in base_tools:\n",
    "        last_base_tools = base_tools[last_tool_name]\n",
    "        if type(last_base_tools).__name__ == \"str\":\n",
    "            # get published or compatible tools for the last tool in a sequence of tools\n",
    "            last_base_tools = last_base_tools.split(\",\")\n",
    "    # get predicted tools\n",
    "    p_tools = get_predicted_tools(last_base_tools, pred_tool_ids, topk)\n",
    "    sorted_c_t, sorted_c_v = sort_by_usage(p_tools, class_weights, dictionary)\n",
    "    return sorted_c_t, sorted_c_v\n",
    "\n",
    "def compute_recommendations(model, tool_sequence, labels, dictionary, reverse_dictionary, class_weights, topk=10, max_seq_len=25):\n",
    "    tl_seq = tool_sequence.split(\",\")\n",
    "    last_tool_name = reverse_dictionary[str(tl_seq[-1])]\n",
    "    sample = np.zeros(max_seq_len)\n",
    "    weight_val = list(class_weights.values())\n",
    "    weight_val = np.reshape(weight_val, (len(weight_val),))\n",
    "    for idx, tool_id in enumerate(tl_seq):\n",
    "        sample[idx] = int(tool_id)\n",
    "    sample_reshaped = np.reshape(sample, (1, max_seq_len))\n",
    "    tool_sequence_names = [reverse_dictionary[str(tool_pos)] for tool_pos in tool_sequence.split(\",\")]\n",
    "    # predict next tools for a test path\n",
    "    prediction = model.predict(sample_reshaped, verbose=0)\n",
    "    nw_dimension = prediction.shape[1]\n",
    "    prediction = np.reshape(prediction, (nw_dimension,))\n",
    "    \n",
    "    half_len = int(nw_dimension / 2)\n",
    "    \n",
    "    pub_t, pub_v = separate_predictions(standard_connections, prediction[:half_len], last_tool_name, weight_val, topk)\n",
    "    # get recommended tools from normal workflows\n",
    "    c_t, c_v = separate_predictions(compatible_tools, prediction[half_len:], last_tool_name, weight_val, topk)\n",
    "    # combine predictions coming from different workflows\n",
    "    # promote recommended tools coming from published workflows\n",
    "    # to the top and then show other recommendations\n",
    "    print()\n",
    "    tool_seq_name = \",\".join(tool_sequence_names)\n",
    "    print(\"Current tool sequence: \")\n",
    "    print()\n",
    "    print(tool_seq_name)\n",
    "    print()\n",
    "    print(\"Overall recommendations: \")\n",
    "    print()\n",
    "    pub_t.extend(c_t)\n",
    "    pub_v.extend(c_v)\n",
    "    # remove duplicates if any\n",
    "    pub_t = list(dict.fromkeys(pub_t))\n",
    "    pub_v = list(dict.fromkeys(pub_v))\n",
    "    print(pub_t)\n",
    "    \n",
    "    ids_tools = dict()\n",
    "    for key in pub_t:\n",
    "        ids_tools[key] = dictionary[key]\n",
    "    print()\n",
    "    print(\"Recommended tool ids:\")\n",
    "    print()\n",
    "    for i in ids_tools:\n",
    "        print(i + \"(\" + str(ids_tools[i]) + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpack trained model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kumara/miniconda3/envs/tool_prediction_cnn_wc/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"data/tool_recommendation_model.hdf5\"\n",
    "trained_model = h5py.File(model_path, 'r')\n",
    "model_config = json.loads(trained_model.get('model_config').value)\n",
    "dictionary = json.loads(trained_model.get('data_dictionary').value)\n",
    "class_weights = json.loads(trained_model.get('class_weights').value)\n",
    "standard_connections = json.loads(trained_model.get('standard_connections').value)\n",
    "compatible_tools = json.loads(trained_model.get('compatible_tools').value)\n",
    "loaded_model = model_from_json(model_config)\n",
    "model, dictionary, reverse_dictionary = create_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indices of tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'fastq_groomer', '2': 'sam_bw_filter', '3': 'find_in_reference', '4': 'cshl_find_and_replace', '5': 'gatk2_variant_annotator', '6': 'trimmer', '7': 'gtf2bedgraph', '8': 'Summary_Statistics1', '9': 'get_flanks1', '10': 'modencode_peakcalling_macs2', '11': 'macs2_callpeak', '12': 'cshl_cut_tool', '13': 'EMBOSS: water107', '14': 'bedtools_subtractbed', '15': 'deeptools_correctGCBias', '16': 'glimmer_knowlegde-based', '17': 'bcftools_view', '18': 'gops_subtract_1', '19': 'cshl_sort_header', '20': 'gemini_load', '21': 'deeptools_bamCoverage', '22': 'rseqc_bam2wig', '23': 'r_correlation_matrix', '24': 'allele_counts_1', '25': 'bamFilter', '26': 'ncbi_blastp_wrapper', '27': 'cshl_multijoin', '28': 'htseq-count', '29': 'bgchem_fragment_merger', '30': 'snpSift_geneSets', '31': 'IDFilter', '32': 'gatk2_variant_select', '33': 'bams2ratio', '34': 'CONVERTER_bed_to_bgzip_0', '35': 'bedtools_intersectbed_bam', '36': 'ctb_change_title', '37': 'bedtools_intersectBed', '38': 'bedtools_genomecoveragebed_bedgraph', '39': 'peakcalling_macs', '40': 'fastq_to_fasta_python', '41': 'antismash', '42': 'deseq2_single', '43': 'Cut1', '44': 'Count1', '45': 'glimmer_build-icm', '46': 'methtools_plot', '47': 'cshl_easyjoin', '48': 'IDPosteriorErrorProbability', '49': 'sam_merge2', '50': 'methtools_filter', '51': 'CONVERTER_bed_gff_or_vcf_to_bigwig_0', '52': 'vcftools_merge', '53': 'gops_coverage_1', '54': 'gatk2_haplotype_caller', '55': 'join1', '56': 'deeptools_bigwigCompare', '57': 'gatk2_variant_apply_recalibration', '58': 'Show beginning1', '59': 'PicardASMetrics', '60': 'EMBOSS: transeq101', '61': 'meme_meme', '62': 'CONVERTER_interval_to_bedstrict_0', '63': 'openms_id_file_converter', '64': 'bowtie2', '65': 'snpEff', '66': 'samtools_rmdup', '67': 'EMBOSS: newseq59', '68': 'deeptools_bamFingerprint', '69': 'vt_normalize', '70': 'rmcontamination', '71': 'cuffdiff', '72': 'picard_ARRG', '73': 'ctb_chemfp_mol2fps', '74': 'XTandemAdapter', '75': 'gemini_interactions', '76': 'bedtools_coveragebed_counts', '77': 'CONVERTER_Bam_Bai_0', '78': 'gtf_filter_by_attribute_values_list', '79': 'msconvert3_raw', '80': 'varscan', '81': 'samtools_flagstat', '82': 'barchart_gnuplot', '83': 'Show tail1', '84': 'rgPicardMarkDups', '85': 'gemini_windower', '86': 'bed_to_bigBed', '87': 'eukaryotic_ncbi_submission', '88': 'cshl_fastx_trimmer', '89': 'cshl_fastq_to_fasta', '90': 'translate_bed_sequences', '91': 'samtools_mpileup', '92': 'proteomics_search_tandem_1', '93': 'cshl_awk_tool', '94': 'bam2wig', '95': 'filter_bed_on_splice_junctions', '96': 'random_lines1', '97': 'heatmapper', '98': 'Add_a_column1', '99': 'cor2', '100': 'ctb_simsearch', '101': 'deeptools_computeMatrix', '102': 'cat1', '103': 'EMBOSS: geecee41', '104': 'deeptools_heatmapper', '105': 'wc_gnu', '106': 'fasta_compute_length', '107': 'ctb_remSmall', '108': 'cshl_fastx_clipper', '109': 'bwa_mem', '110': 'gemini_comp_hets', '111': 'cshl_uniq_tool', '112': 'cufflinks', '113': 'gemini_burden', '114': 'ctb_remIons', '115': 'bedtools_multiintersectbed', '116': 'tab2fasta', '117': 'tophat2', '118': 'Convert characters1', '119': 'CONVERTER_bedgraph_to_bigwig', '120': 'silac_analyzer', '121': 'cshl_sed_tool', '122': 'bedtools_bamtobed', '123': 'cshl_word_list_grep', '124': 'gatk2_reduce_reads', '125': 'methtools_calling', '126': 'gops_intersect_1', '127': 'smooth_running_window', '128': 'fragmenter', '129': 'CONVERTER_bed_to_gff_0', '130': 'fastq_filter', '131': 'gatk2_indel_realigner', '132': 'fasta_filter_by_length', '133': 'ctb_filter', '134': 'mergeCols1', '135': 'scaffold2fasta', '136': 'bedtools_mergebed', '137': 'Remove beginning1', '138': 'methtools_destrand', '139': 'bismark_bowtie', '140': 'cuffmerge', '141': 'snpSift_annotate', '142': 'correctGCBias', '143': 'cshl_grep_tool', '144': 'ncbi_blastn_wrapper', '145': 'IDMapper', '146': 'vcftools_isec', '147': 'sed_stream_editor', '148': 'histogram_rpy', '149': 'CONVERTER_interval_to_bed_0', '150': 'DatamashTranspose', '151': 'augustus', '152': 'CONVERTER_interval_to_bgzip_0', '153': 'dt_profiler', '154': 'computeMatrix', '155': 'openms_id_mapper', '156': 'PeptideIndexer', '157': 'rsem_calculate_expression', '158': 'proteomics_search_protein_prophet_1', '159': 'prokaryotic_ncbi_submission', '160': 'bg_uniq', '161': 'blockbuster', '162': 'ssake', '163': 'peakcalling_macs14', '164': 'sam2interval', '165': 'proteomics_search_peptide_prophet_1', '166': 'ctb_online_data_fetch', '167': 'deeptools_profiler', '168': 'htseq_count', '169': 'Extract genomic DNA 1', '170': 'fastqc', '171': 'infernal_cmsearch', '172': 'gatk2_variant_recalibrator', '173': 'Filter1', '174': 'deseq2', '175': 'EMBOSS: fuzzpro38', '176': 'Grep1', '177': 'bedtools_bamtofastq', '178': 'FidoAdapter', '179': 'gemini_de_novo', '180': 'gatk2_realigner_target_creator', '181': 'wig_to_bigWig', '182': 'cshl_fasta_formatter', '183': 'ctb_compound_convert', '184': 'sample_seqs', '185': 'ncbi_tblastn_wrapper', '186': 'gemini_pathways', '187': 'freebayes', '188': 'CONVERTER_gff_to_bed_0', '189': 'Paste1', '190': 'picard_ReorderSam', '191': 'EMBOSS: shuffleseq87', '192': 'bamCoverage_deepTools', '193': 'vcfallelicprimitives', '194': 'methtools_tiling', '195': 'tophat', '196': 'XY_Plot_1', '197': 'Datamash', '198': 'vcffilter', '199': 'blockclust', '200': 'charts', '201': 'deeptools_bamCorrelate', '202': 'addValue', '203': 'bed2gff1', '204': 'gemini_query', '205': 'sam_to_bam', '206': 'seq_filter_by_id', '207': 'gff2bed1', '208': 'ProteinQuantifier', '209': 'gatk2_print_reads', '210': 'comp1', '211': 'fasta2tab', '212': 'sort1', '213': 'Extract_features1', '214': 'heatmapper_deepTools', '215': 'methtools_dmr', '216': 'Grouping1', '217': 'cshl_awk_replace_in_column', '218': 'ncbi_makeblastdb', '219': 'naive_variant_caller', '220': 'Remove_ending', '221': 'FalseDiscoveryRate', '222': 'hgv_david', '223': 'blastxml_to_tabular', '224': 'bismark_bowtie2', '225': 'blastxml_to_top_descr', '226': 'gops_join_1', '227': 'openms_protein_quantifier', '228': 'trim_galore', '229': 'FeatureFinderMultiplex', '230': 'deeptools_computeGCBias', '231': 'samtools_sort', '232': 'EMBOSS: fuzztran39', '233': 'gatk2_base_recalibrator', '234': 'bwa_wrapper', '235': 'bam_to_sam', '236': 'IDMerger', '237': 'deeptools_bamCompare', '238': 'fastq_quality_trimmer', '239': 'bamCompare_deepTools', '240': 'rsem_prepare_reference', '241': 'snpSift_filter'}\n"
     ]
    }
   ],
   "source": [
    "print(reverse_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['addValue']\n",
      "\n",
      "['join1', 'Cut1', 'Add_a_column1']\n",
      "\n",
      "\n",
      "Current tool sequence: \n",
      "\n",
      "Paste1\n",
      "\n",
      "Overall recommendations: \n",
      "\n",
      "['addValue', 'Cut1', 'join1', 'Add_a_column1']\n",
      "\n",
      "Recommended tool ids:\n",
      "\n",
      "addValue(202)\n",
      "Cut1(43)\n",
      "join1(55)\n",
      "Add_a_column1(98)\n"
     ]
    }
   ],
   "source": [
    "########### \n",
    "####### Tools from training material\n",
    "# Assembly: \n",
    "# (https://training.galaxyproject.org/training-material/topics/assembly/tutorials/debruijn-graph-assembly/tutorial.html)\n",
    "# (504) Spades -> 'bandage_info', 'fasta-stats', 'bandage_image', 'fasta_filter_by_length', 'abricate', 'quast', 'mlst' ... \n",
    "# (1113) Velveth -> velvetg\n",
    "# (https://training.galaxyproject.org/training-material/topics/assembly/tutorials/unicycler-assembly/tutorial.html)\n",
    "# (35) Unicycler -> 'bandage_info', 'glimmer_build-icm', 'glimmer_knowlegde-based', 'bandage_image', 'transdecoder', 'minimap2', 'antismash', 'fasta_filter_by_length' ...\n",
    "\n",
    "## Computational chemistry\n",
    "# (84) ctb_remDuplicates -> ctb_remIons \n",
    "# (84,1204) ctb_remDuplicates,ctb_remIons -> 'ctb_chemfp_mol2fps', 'ctb_compound_convert'\n",
    "# (84,1204,626) ctb_remDuplicates,ctb_remIons,ctb_chemfp_mol2fps -> 'ctb_chemfp_butina_clustering', 'ctb_simsearch', 'ctb_chemfp_nxn_clustering', 'comp1'\n",
    "# (https://training.galaxyproject.org/training-material/topics/computational-chemistry/tutorials/cheminformatics/tutorial.html)\n",
    "\n",
    "## RAD-seq\n",
    "# (https://training.galaxyproject.org/training-material/topics/ecology/tutorials/ref-based-rad-seq/tutorial.html)\n",
    "# (583) stacks_procrad -> 'bwa', 'bwa_wrapper', 'Grep1', 'stacks_denovomap', 'fastqc', 'fastq_filter'\n",
    "\n",
    "## Epigenetics\n",
    "# (https://training.galaxyproject.org/training-material/topics/epigenetics/tutorials/atac-seq/tutorial.html)\n",
    "# (1344,775) cutadapt,bowtie2 => samtools_flagstat', 'picard_MarkDuplicates', 'picard_AddOrReplaceReadGroups', 'macs2_callpeak','bg_sortmerna', 'multiqc', 'hisat2', 'trim_galore', 'bowtie2' ...\n",
    "# (1344,775,292) cutadapt,bowtie2,picard_MarkDuplicates -> 'picard_ReorderSam', 'gatk4_mutect2', 'samtools_rmdup'\n",
    "# (1344,775,292,473) cutadapt,bowtie2,picard_MarkDuplicates,genrich -> 'pygenomeTracks'\n",
    "#\n",
    "# (https://training.galaxyproject.org/training-material/topics/epigenetics/tutorials/methylation-seq/tutorial.html)\n",
    "# (639) bwameth -> 'samtools_rmdup', 'samtools_sort', 'bam_to_sam', 'pileometh' ..\n",
    "# (639,1451) bwameth,pileometh -> 'deeptools_compute_matrix', 'tp_sed_tool', 'Filter1', 'metilene', 'Remove beginning1', 'wig_to_bigWig'\n",
    "# ()\n",
    "# (775) bowtie2 -> samtools_flagstat', 'picard_MarkDuplicates', 'picard_AddOrReplaceReadGroups ... \n",
    "# (775,1231) bowtie2,deeptools_multi_bam_summary -> 'deeptools_plot_pca', 'r_correlation_matrix' ...\n",
    "# (https://training.galaxyproject.org/training-material/topics/epigenetics/tutorials/formation_of_super-structures_on_xi/tutorial.html)\n",
    "\n",
    "# (775,170) bowtie2,hicexplorer_hicbuildmatrix -> 'hicexplorer_hicsummatrices', 'hicexplorer_hicplotviewpoint', 'tp_sed_tool', 'hicexplorer_hiccorrectmatrix', 'hicexplorer_hicmergematrixbins', 'hicexplorer_hicpca' ..\n",
    "# (775,170,669) bowtie2,hicexplorer_hicbuildmatrix,hicexplorer_hicmergematrixbins -> 'hicexplorer_hiccorrectmatrix', 'hicexplorer_hicplottads', 'hicexplorer_hicplotmatrix'\n",
    "# (https://training.galaxyproject.org/training-material/topics/epigenetics/tutorials/hicexplorer/tutorial.html)\n",
    "\n",
    "# (232) minfi_read450k -> 'minfi_getbeta'\n",
    "\n",
    "\n",
    "## Genome annotation\n",
    "# (https://training.galaxyproject.org/training-material/topics/genome-annotation/tutorials/annotation-with-maker/tutorial.html)\n",
    "# (1157) maker -> 'gffread', 'maker_map_ids', 'jcvi_gff_stats'\n",
    "# (https://training.galaxyproject.org/training-material/topics/genome-annotation/tutorials/annotation-with-prokka/tutorial.html)\n",
    "# (94) prokka -> 'mlst', 'jbrowse', 'taxonomy_krona_chart' ...\n",
    "\n",
    "\n",
    "## Imaging\n",
    "# (https://training.galaxyproject.org/training-material/topics/imaging/tutorials/hela-screen-analysis/tutorial.html)\n",
    "# (415) ip_filter_standard -> 'ip_histogram_equalization', 'ip_threshold', 'ip_count_objects\n",
    "# (415,309) ip_filter_standard,ip_threshold -> ip_binary_to_labelimage', 'ip_2d_split_binaryimage_by_watershed', 'ip_count_objects', 'ip_convertimage'\n",
    "# (415,309,992) ip_filter_standard,ip_threshold,ip_2d_split_binaryimage_by_watershed -> 'ip_2d_filter_segmentation_by_features', 'ip_2d_feature_extraction'\n",
    "\n",
    "\n",
    "## Mass spectrometry\n",
    "# (630) mass_spectrometry_imaging_preprocessing -> 'mass_spectrometry_imaging_combine', 'mass_spectrometry_imaging_preprocessing'\n",
    "# (630,1386) mass_spectrometry_imaging_preprocessing,mass_spectrometry_imaging_combine -> 'maldi_quant_preprocessing', 'mass_spectrometry_imaging_preprocessing', 'mass_spectrometry_imaging_qc' ...\n",
    "# (711) search_gui -> peptide_shaker\n",
    "# (711,1411) search_gui,peptide_shaker -> 'mz_to_sqlite', 'Remove beginning1', 'tp_replace_in_column', 'unipept', proteomics_moff ...\n",
    "\n",
    "\n",
    "## Single cell\n",
    "# (531) raceid_main -> 'seurat','raceid_trajectory'\n",
    "# (531,691) raceid_main,raceid_trajectory -> 'raceid_inspecttrajectory'\n",
    "# (141,685) raceid_inspectclusters,__BUILD_LIST__ -> 'picard_MarkDuplicates', 'hisat2', 'stringtie_merge', 'cutadapt', 'tp_cat'\n",
    "# (89) raceid_filtnormconf -> 'raceid_clustering', '__BUILD_LIST__'\n",
    "# (89,270) raceid_filtnormconf,raceid_clustering -> 'raceid_trajectory', 'raceid_inspectclusters'\n",
    "# (638) scanpy_regress_variable -> scanpy_scale_data \n",
    "# (638,739) scanpy_regress_variable,scanpy_scale_data -> 'scanpy_run_pca', 'scanpy_find_variable_genes'\n",
    "# (638,739,505) scanpy_regress_variable,scanpy_scale_data,scanpy_run_pca -> 'scanpy_compute_graph', 'scanpy_plot', 'scanpy_run_tsne', 'scanpy_plot_embed'\n",
    "\n",
    "# (https://training.galaxyproject.org/training-material/topics/transcriptomics/tutorials/scrna-preprocessing-tenx/tutorial.html)\n",
    "# (728) rna_starsolo -> 'dropletutils', 'multiqc'\n",
    "# (728,306) rna_starsolo,dropletutils -> 'scanpy_read_10x', 'scanpy_cluster_reduce_dimension', 'seurat_read10x', 'anndata_import', 'scanpy_plot', 'raceid_filtnormconf'\n",
    "\n",
    "\n",
    "## Variant calling\n",
    "# (https://training.galaxyproject.org/training-material/topics/variant-analysis/tutorials/microbial-variants/tutorial.html)\n",
    "# (1076) snippy -> 'bedtools_intersectbed', 'vcfvcfintersect', 'Remove beginning1', 'snippy_core', 'qualimap_bamqc', 'freebayes', 'jbrowse', 'vcfcombine'\n",
    "\n",
    "# https://training.galaxyproject.org/training-material/topics/variant-analysis/tutorials/somatic-variants/tutorial.html\n",
    "# (57,712,991,629) trimmomatic,bwa_mem,samtools_rmdup,bamleftalign -> 'samtool_filter2', 'ivar_variants', 'freebayes', 'varscan_somatic', 'deeptools_bam_coverage', 'fastqc', 'ngsutils_bam_filter', 'bamFilter', 'rgPicFixMate', 'samtools_calmd'\n",
    "# (57,712,991,629,273) trimmomatic,bwa_mem,samtools_rmdup,bamleftalign,varscan_somatic -> 'bcftools_norm', 'gemini_annotate', 'vt_normalize', 'vcffilter2', 'vcfallelicprimitives', 'snpEff'\n",
    "\n",
    "# (https://training.galaxyproject.org/training-material/topics/variant-analysis/tutorials/dip/tutorial.html)\n",
    "# (988) freebayes -> 'vcfallelicprimitives', 'bcftools_norm', 'custom_pro_db', 'vcfvcfintersect'\n",
    "# (988,436) freebayes,vcfallelicprimitives -> 'vt_normalize', 'snpSift_filter', 'snpSift_annotate', 'snpEff'\n",
    "# (988,436,32) freebayes,vcfallelicprimitives,snpEff -> 'gemini_load', 'mimodd_varreport', 'snpSift_extractFields\n",
    "\n",
    "\n",
    "# Transcriptomics\n",
    "#(https://training.galaxyproject.org/training-material/topics/transcriptomics/tutorials/small_ncrna_clustering/tutorial.html)\n",
    "# (1459,1473,1522) samtools_sort,blockclust,sort1 -> 'cshl_awk_tool', 'Show beginning1', 'tp_awk_tool', 'blockbuster'\n",
    "\n",
    "# (https://training.galaxyproject.org/training-material/topics/transcriptomics/tutorials/ref-based/tutorial.html)\n",
    "# (1344) cutadapt -> 'umi_tools_extract', 'fastq_paired_end_interlacer', 'chira_collapse', 'rna_star',\n",
    "# (1344,484) cutadapt,rna_star -> 'featurecounts', 'multiqc', 'htseq_count', 'rseqc_infer_experiment', 'samtools_stats', 'bamFilter',\n",
    "# (1344,484,1209) cutadapt,rna_star,featurecounts -> 'multiqc', 'deseq2', 'tp_sort_header_tool', 'bamFilter', 'collection_column_join ...\n",
    "\n",
    "# Single-cell HiC\n",
    "# 508 schicexplorer_schicqualitycontrol -> 'schicexplorer_schicnormalize'\n",
    "# schicexplorer_schicnormalize -> 'schicexplorer_schicclustersvl', 'schicexplorer_schicconsensusmatrices', 'schicexplorer_schicplotclusterprofiles'\n",
    "# (13,743) schicexplorer_schicnormalize,schicexplorer_schicclustersvl -> 'schicexplorer_schicplotclusterprofiles', 'schicexplorer_schicconsensusmatrices'\n",
    "\n",
    "\n",
    "# Animal detection on acoustic recording\n",
    "# (1224) vigiechiro_idvalid -> 'vigiechiro_bilanenrichipf', 'vigiechiro_bilanenrichirp'\n",
    "\n",
    "topk = 10 # set the maximum number of recommendations #\"980,1300,465,937,977 \n",
    "# ctb - 45,244,180,379\n",
    "tool_seq = \"189\" # give tools ids in a sequence and see the recommendations. To know all the tool ids, \n",
    "                     # please print the variable 'reverse_dictionary'\n",
    "compute_recommendations(model, tool_seq, \"\", dictionary, reverse_dictionary, class_weights, topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
