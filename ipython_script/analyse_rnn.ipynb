{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8439389d-c89d-4d0a-90ae-fbe6706cd498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 16:25:53.289185: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-09 16:25:53.289205: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0256fa07-f9b1-4e18-bed2-a0ab93ef20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = (20, 20)\n",
    "font = {'family': 'serif', 'size': 20}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "batch_size = 10\n",
    "test_batches = 1\n",
    "n_topk = 2\n",
    "max_seq_len = 25\n",
    "\n",
    "base_path = \"../log_08_08_22_rnn/\"\n",
    "predict_rnn = True\n",
    "\n",
    "#base_path = \"log_08_08_22_rnn/\"\n",
    "#predict_rnn = True # set to True for RNN model\n",
    "\n",
    "# log_08_08_22_2 (finish time: 40,000 steps in 158683.60082054138 seconds)\n",
    "# log_08_08_22_rnn (finish time: 40,000 steps in 173480.83078551292 seconds)\n",
    "\n",
    "#\"log_03_08_22_1/\" Balanced data with really selection of low freq tools - random choice\n",
    "# RNN: log_01_08_22_3_rnn\n",
    "# Transformer: log_01_08_22_0\n",
    "\n",
    "model_number = 40000\n",
    "model_path = base_path + \"saved_model/\" + str(model_number) + \"/tf_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd224834-b321-4f82-880b-83ea6acca632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 16:26:02.436177: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-09 16:26:02.436537: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-09 16:26:02.437270: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (anupkumar-HP-ProBook-450-G5): /proc/driver/nvidia/version does not exist\n",
      "2022-08-09 16:26:02.452210: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def remove_file(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read a file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        file_content = json.loads(json_file.read())\n",
    "    return file_content\n",
    "\n",
    "\n",
    "def write_file(file_path, content):\n",
    "    \"\"\"\n",
    "    Write a file\n",
    "    \"\"\"\n",
    "    remove_file(file_path)\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json_file.write(json.dumps(content))\n",
    "\n",
    "\n",
    "r_dict = read_file(base_path + \"data/rev_dict.txt\")\n",
    "f_dict = read_file(base_path + \"data/f_dict.txt\")\n",
    "\n",
    "path_test_data = base_path + \"saved_data/test.h5\"\n",
    "\n",
    "file_obj = h5py.File(path_test_data, 'r')\n",
    "\n",
    "test_input = np.array(file_obj[\"input\"])\n",
    "test_target = np.array(file_obj[\"target\"])\n",
    "\n",
    "class_weights = read_file(base_path + \"data/class_weights.txt\")\n",
    "compatible_tools = read_file(base_path + \"data/compatible_tools.txt\")\n",
    "\n",
    "#tool_freq = utils.read_file(base_path + \"data/freq_dict_names.txt\")\n",
    "published_connections = read_file(base_path + \"data/published_connections.txt\")\n",
    "\n",
    "c_weights = list(class_weights.values())\n",
    "\n",
    "c_weights = tf.convert_to_tensor(c_weights, dtype=tf.float32)\n",
    "\n",
    "te_lowest_t_ids = read_file(base_path + \"data/te_lowest_t_ids.txt\")\n",
    "lowest_t_ids = [int(item) for item in te_lowest_t_ids.split(\",\")]\n",
    "tool_tr_freq = read_file(base_path + \"data/all_sel_tool_ids.txt\")\n",
    "\n",
    "all_sel_tool_ids = read_file(base_path + \"data/all_sel_tool_ids.txt\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0524ee9c-2b57-432b-a05c-5533271ebf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ae2b83-55f4-4075-8c63-babcf9b86d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generated_attention(attention_weights, i_names, f_dict, r_dict):\n",
    "\n",
    "    #print(attention_weights.shape)\n",
    "    attention_heads = tf.squeeze(attention_weights, 0)\n",
    "    n_heads = attention_heads.shape[1]\n",
    "    i_names = i_names.split(\",\")\n",
    "    in_tokens = i_names\n",
    "    out_tokens = i_names\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "\n",
    "    for h, head in enumerate(attention_heads):\n",
    "      ax = fig.add_subplot(2, 4, h+1)\n",
    "      plot_attention_head(in_tokens, out_tokens, head)\n",
    "      ax.set_xlabel(f'Head {h+1}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_attention_head(in_tokens, out_tokens, attention):\n",
    "  # The plot is of the attention when a token was generated.\n",
    "  # The model didn't generate `<START>` in the output. Skip it.\n",
    "  #translated_tokens = translated_tokens[1:]\n",
    "  #print(attention)\n",
    "  ax = plt.gca()\n",
    "  ax.matshow(attention[:len(in_tokens), :len(out_tokens)])\n",
    "  #ax.matshow(attention)\n",
    "\n",
    "  ax.set_xticks(range(len(in_tokens)))\n",
    "  ax.set_yticks(range(len(out_tokens)))\n",
    "\n",
    "  ax.set_xticklabels(in_tokens, rotation=90)\n",
    "  ax.set_yticklabels(out_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9390e063-d2c1-4a5b-83f2-1ec4235a81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss_acc():\n",
    "    epo_tr_batch_loss = read_file(base_path + \"data/epo_tr_batch_loss.txt\").split(\",\")\n",
    "\n",
    "    #print(len(epo_tr_batch_loss))\n",
    "    epo_tr_batch_loss = [np.round(float(item), 4) for item in epo_tr_batch_loss]\n",
    "\n",
    "    epo_tr_batch_acc = read_file(base_path + \"data/epo_tr_batch_acc.txt\").split(\",\")\n",
    "    epo_tr_batch_acc = [np.round(float(item), 4) for item in epo_tr_batch_acc]\n",
    "\n",
    "    epo_te_batch_loss = read_file(base_path + \"data/epo_te_batch_loss.txt\").split(\",\")\n",
    "    epo_te_batch_loss = [np.round(float(item), 4) for item in epo_te_batch_loss]\n",
    "\n",
    "    epo_te_batch_acc = read_file(base_path + \"data/epo_te_precision.txt\").split(\",\")\n",
    "    epo_te_batch_acc = [np.round(float(item), 4) for item in epo_te_batch_acc]\n",
    "\n",
    "    plot_loss_acc(epo_tr_batch_loss, epo_tr_batch_acc, \"training\")\n",
    "    plot_loss_acc(epo_te_batch_loss, epo_te_batch_acc, \"test\")\n",
    "\n",
    "    epo_te_low_batch_acc = read_file(base_path + \"data/epo_low_te_precision.txt\").split(\",\")\n",
    "    epo_te_low_batch_acc = [np.round(float(item), 4) for item in epo_te_low_batch_acc]\n",
    "\n",
    "    plot_low_te_prec(epo_te_low_batch_acc, \"Low test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa590092-8a14-485f-ab29-612852d95e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 16:26:06.039560: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:06.424548: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:06.990829: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:07.113029: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:07.904660: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:08.129983: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:08.426099: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:08.760835: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:08.779939: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:09.213889: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:09.319760: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:09.340516: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:09.376422: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:10.006958: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:10.028037: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:11.258186: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:11.279095: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:11.341020: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:11.359947: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:11.679432: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:11.699689: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:12.151848: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:12.170316: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:12.389306: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:12.842149: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:12.918116: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:12.938580: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2022-08-09 16:26:12.973158: W tensorflow/core/common_runtime/graph_constructor.cc:805] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n"
     ]
    }
   ],
   "source": [
    "def load_model():\n",
    "    return tf.saved_model.load(model_path)\n",
    "tf_loaded_model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e90a9344-73c6-4577-a751-aed336aa5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_balanced_tr_y(x_seqs, y_labels, ulabels_tr_y_dict):\n",
    "    batch_y_tools = list(ulabels_tr_y_dict.keys())\n",
    "    random.shuffle(batch_y_tools)\n",
    "    label_tools = list()\n",
    "    rand_batch_indices = list()\n",
    "\n",
    "    for l_tool in batch_y_tools:\n",
    "        seq_indices = ulabels_tr_y_dict[l_tool]\n",
    "        random.shuffle(seq_indices)\n",
    "        \n",
    "        if seq_indices[0] not in rand_batch_indices:\n",
    "            rand_batch_indices.append(seq_indices[0])\n",
    "            label_tools.append(l_tool)\n",
    "        if len(rand_batch_indices) == batch_size:\n",
    "            break\n",
    "    \n",
    "    x_batch_train = x_seqs[rand_batch_indices]\n",
    "    y_batch_train = y_labels[rand_batch_indices]\n",
    "\n",
    "    unrolled_x = tf.convert_to_tensor(x_batch_train, dtype=tf.int64)\n",
    "    unrolled_y = tf.convert_to_tensor(y_batch_train, dtype=tf.int64)\n",
    "    return unrolled_x, unrolled_y, label_tools, rand_batch_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad68747f-5586-46d3-bb27-ce601e6907b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "991ec9f5-77a9-4278-903e-2ee8ac1d5ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_low_freq_seq():\n",
    "    \n",
    "    \n",
    "    low_te_data = test_input[lowest_t_ids]\n",
    "    low_te_labels = test_target[lowest_t_ids]\n",
    "    #print(\"Test lowest ids\", low_te_data.shape, low_te_labels.shape)\n",
    "    #low_te_pred_batch, low_att_weights = tf_loaded_model([low_te_data], training=False)\n",
    "    low_topk = 5\n",
    "    low_te_precision = list()\n",
    "    for i, (low_inp, low_tar) in enumerate(zip(low_te_data, low_te_labels)):\n",
    "        if predict_rnn is True:\n",
    "            low_prediction = tf_loaded_model([low_inp], training=False)\n",
    "        else:\n",
    "            low_prediction, att_weights = tf_loaded_model([low_inp], training=False)\n",
    "        #print(low_prediction.shape)\n",
    "        \n",
    "        low_label_pos = np.where(low_tar > 0)[0]\n",
    "        low_topk = len(low_label_pos)\n",
    "        low_topk_pred = tf.math.top_k(low_prediction, k=low_topk, sorted=True)\n",
    "        low_topk_pred = low_topk_pred.indices.numpy()[0]\n",
    "        \n",
    "        low_label_pos_tools = [r_dict[str(item)] for item in low_label_pos if item not in [0, \"0\"]]\n",
    "        low_pred_label_pos_tools = [r_dict[str(item)] for item in low_topk_pred if item not in [0, \"0\"]]\n",
    "\n",
    "        low_intersection = list(set(low_label_pos_tools).intersection(set(low_pred_label_pos_tools)))\n",
    "        low_pred_precision = float(len(low_intersection)) / len(low_label_pos)\n",
    "        low_te_precision.append(low_pred_precision)\n",
    "        \n",
    "        #low_inp = low_inp.numpy()\n",
    "        low_inp_pos = np.where(low_inp > 0)[0]\n",
    "\n",
    "        print(\"Low: test tool sequence: {}\".format([r_dict[str(int(item))] for item in low_inp[low_inp_pos]]))\n",
    "        print()\n",
    "        print(\"Low: True labels: {}\".format(low_label_pos_tools))\n",
    "        print()\n",
    "        print(\"Low: Predicted labels: {}, Precision: {}\".format(low_pred_label_pos_tools, low_pred_precision))\n",
    "        print(\"-----------------\")\n",
    "        print()\n",
    "    \n",
    "    if len(lowest_t_ids) > 0:\n",
    "        print(\"Low test prediction precision: {}\".format(np.mean(low_te_precision)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23c48f7-8ff3-4342-85c2-efe1e3ffe42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_tool_in_tr(r_dict):\n",
    "    \n",
    "\n",
    "    freq_dict = dict()\n",
    "    freq_dict_names = dict()\n",
    "\n",
    "    for tool_id in all_sel_tool_ids:\n",
    "        if tool_id not in freq_dict:\n",
    "            freq_dict[tool_id] = 0\n",
    "\n",
    "        if tool_id not in freq_dict_names:\n",
    "            freq_dict_names[r_dict[str(int(tool_id))]] = 0\n",
    "\n",
    "        freq_dict[tool_id] += 1\n",
    "        freq_dict_names[r_dict[str(int(tool_id))]] += 1\n",
    "\n",
    "    s_freq = dict(sorted(freq_dict.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    s_freq_names = dict(sorted(freq_dict_names.items(), key=lambda kv: kv[1], reverse=True))\n",
    "\n",
    "\n",
    "    write_file(base_path + \"data/s_freq_names.txt\", s_freq_names)\n",
    "    write_file(base_path + \"data/s_freq.txt\", s_freq)\n",
    "\n",
    "    return s_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e7626fc-8703-4aac-afa0-c72a41aa6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_u_tr_labels(y_tr):\n",
    "    labels = list()\n",
    "    labels_pos_dict = dict()\n",
    "    for i, item in enumerate(y_tr):\n",
    "        label_pos = np.where(item > 0)[0]\n",
    "        labels.extend(label_pos)\n",
    "        for label in label_pos:\n",
    "            if label not in labels_pos_dict:\n",
    "                labels_pos_dict[label] = list()\n",
    "            labels_pos_dict[label].append(i)\n",
    "\n",
    "    u_labels = list(set(labels))\n",
    "    \n",
    "    for item in labels_pos_dict:\n",
    "        labels_pos_dict[item] = list(set(labels_pos_dict[item]))\n",
    "    return u_labels, labels_pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06683e24-e729-458e-b9fb-a1d4cd1f650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq():\n",
    "\n",
    "    #visualize_loss_acc()\n",
    "\n",
    "    \n",
    "    #sys.exit()\n",
    "\n",
    "    #verify_training_sampling(tool_tr_freq, r_dict)\n",
    "    \n",
    "    #r_dict = read_file(base_path + \"data/rev_dict.txt\")\n",
    "    #f_dict = read_file(base_path + \"data/f_dict.txt\")\n",
    "    \n",
    "    all_tr_label_tools = verify_tool_in_tr(r_dict)\n",
    "\n",
    "    all_tr_label_tools_ids = list(all_tr_label_tools.keys())\n",
    "    all_tr_label_tools_ids = [int(t) for t in all_tr_label_tools_ids]\n",
    "    \n",
    "    \n",
    "    print(test_input.shape, test_target.shape)\n",
    "\n",
    "    \n",
    "    u_te_y_labels, u_te_y_labels_dict = get_u_tr_labels(test_target)\n",
    "\n",
    "    precision = list()\n",
    "    pub_prec_list = list()\n",
    "    error_label_tools = list()\n",
    "\n",
    "    for j in range(test_batches):\n",
    "        #te_x_batch, y_train_batch = sample_balanced(test_input, test_target, ulabels_te_dict)\n",
    "        te_x_batch, y_train_batch, selected_label_tools, bat_ind = sample_balanced_tr_y(test_input, test_target, u_te_y_labels_dict)\n",
    "        #print(j * batch_size, j * batch_size + batch_size)\n",
    "        #te_x_batch = test_input[j * batch_size : j * batch_size + batch_size, :]\n",
    "        #y_train_batch = test_target[j * batch_size : j * batch_size + batch_size, :]\n",
    "\n",
    "        for i, (inp, tar) in enumerate(zip(te_x_batch, y_train_batch)):\n",
    "\n",
    "            t_ip = inp\n",
    "            if len(np.where(inp > 0)[0]) < max_seq_len:\n",
    "                real_prediction = np.where(tar > 0)[0]\n",
    "                target_pos = list(set(all_tr_label_tools_ids).intersection(set(real_prediction)))\n",
    "                #print(\"Real predicted tools: {}, Actual trained labels: {}\".format(real_prediction, target_pos))\n",
    "                #print()\n",
    "                t_ip = tf.convert_to_tensor(t_ip, dtype=tf.int64)\n",
    "                if predict_rnn is True:\n",
    "                    prediction = tf_loaded_model([t_ip], training=False)\n",
    "                else:\n",
    "                    prediction, att_weights = tf_loaded_model([t_ip], training=False)\n",
    "                prediction_wts = tf.math.multiply(c_weights, prediction)\n",
    "\n",
    "                n_topk = len(target_pos)\n",
    "                top_k = tf.math.top_k(prediction, k=n_topk, sorted=True)\n",
    "                top_k_wts = tf.math.top_k(prediction_wts, k=n_topk, sorted=True)\n",
    "\n",
    "                t_ip = t_ip.numpy()\n",
    "                label_pos = np.where(t_ip > 0)[0]\n",
    "\n",
    "                i_names = \",\".join([r_dict[str(item)] for item in t_ip[label_pos]  if item not in [0, \"0\"]])\n",
    "                t_names = \",\".join([r_dict[str(int(item))] for item in target_pos  if item not in [0, \"0\"]])\n",
    "\n",
    "                last_i_tool = [r_dict[str(item)] for item in t_ip[label_pos]][-1]\n",
    "\n",
    "                true_tools = [r_dict[str(int(item))] for item in target_pos]\n",
    "\n",
    "                #print(\"Selected tool in true tools: {}\".format(s_label_tool in true_tools))\n",
    "\n",
    "                pred_tools = [r_dict[str(item)] for item in top_k.indices.numpy()[0]  if item not in [0, \"0\"]]\n",
    "                pred_tools_wts = [r_dict[str(item)] for item in top_k_wts.indices.numpy()[0]  if item not in [0, \"0\"]]\n",
    "\n",
    "                intersection = list(set(true_tools).intersection(set(pred_tools)))\n",
    "\n",
    "                pub_prec = 0.0\n",
    "                pub_prec_wt = 0.0\n",
    "\n",
    "                if last_i_tool in published_connections:\n",
    "                    true_pub_conn = published_connections[last_i_tool]\n",
    "                    #print(\"Test batch {}, True published tools: {}\".format(j+1, true_pub_conn)) \n",
    "                    #print()\n",
    "                    if len(pred_tools) > 0:\n",
    "                        intersection_pub = list(set(true_pub_conn).intersection(set(pred_tools)))\n",
    "                        intersection_pub_wt = list(set(true_pub_conn).intersection(set(pred_tools_wts)))\n",
    "                        pub_prec = float(len(intersection_pub)) / len(pred_tools)\n",
    "                        pub_prec_list.append(pub_prec)\n",
    "                        pub_prec_wt = float(len(intersection_pub_wt)) / len(pred_tools)\n",
    "                    else:\n",
    "                        pub_prec = False\n",
    "                        pub_prec_wt = False\n",
    "\n",
    "                if len(pred_tools) > 0:\n",
    "                    pred_precision = float(len(intersection)) / len(pred_tools)\n",
    "                    precision.append(pred_precision)\n",
    "\n",
    "                if pred_precision < 2.0:\n",
    "            \n",
    "                    print(\"Test batch {}, Tool sequence: {}\".format(j+1, [r_dict[str(item)] for item in t_ip[label_pos]]))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, True tools: {}\".format(j+1, true_tools))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, Predicted top {} tools: {}\".format(j+1, n_topk, pred_tools))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, Predicted top {} tools with weights: {}\".format(j+1, n_topk, pred_tools_wts))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, Precision: {}\".format(j+1, pred_precision)) \n",
    "                    print()\n",
    "                    print(\"Test batch {}, Published precision: {}\".format(j+1, pub_prec))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, Published precision with weights: {}\".format(j+1, pub_prec_wt))\n",
    "                    #error_label_tools.append(select_tools[i])\n",
    "                    print(\"=========================\")\n",
    "                print(\"--------------------------\")\n",
    "                generated_attention(att_weights, i_names, f_dict, r_dict)\n",
    "        \n",
    "                print(\"Batch {} prediction finished ...\".format(j+1))\n",
    "\n",
    "    if test_batches > 0:\n",
    "        print(\"Precision@{}: {}\".format(n_topk, np.mean(precision)))\n",
    "        print(\"Published Precision@{}: {}\".format(n_topk, np.mean(pub_prec_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34f50e20-a934-463a-81b6-4393d36a9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16027192-45ed-4766-b6a1-1d114f23b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_low_freq_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2938e6ae-7a49-45b8-9b11-1af23fd36a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_custom_seq():\n",
    "\n",
    "    n_topk_ind = 20\n",
    "    t_ip = np.zeros((25))\n",
    "    t_ip[0] = int(f_dict[\"DatamashTranspose\"])\n",
    "    t_ip[1] = int(f_dict[\"dropletutils\"])\n",
    "    #t_ip[2] = int(f_dict[\"ip_threshold\"])\n",
    "\n",
    "    last_tool_name = \"dropletutils\"\n",
    "    \n",
    "    \n",
    "    t_ip = tf.convert_to_tensor(t_ip, dtype=tf.int64)\n",
    "    prediction = tf_loaded_model([t_ip], training=False)\n",
    "    prediction_cwts = tf.math.multiply(c_weights, prediction)\n",
    "\n",
    "    top_k = tf.math.top_k(prediction, k=n_topk_ind, sorted=True)\n",
    "    top_k_wts = tf.math.top_k(prediction_cwts, k=n_topk_ind, sorted=True)\n",
    "\n",
    "    t_ip = t_ip.numpy()\n",
    "    label_pos = np.where(t_ip > 0)[0]\n",
    "\n",
    "    i_names = \",\".join([r_dict[str(item)] for item in t_ip[label_pos]  if item not in [0, \"0\"]])\n",
    "\n",
    "    pred_tools = [r_dict[str(item)] for item in top_k.indices.numpy()[0]  if item not in [0, \"0\"]]\n",
    "    pred_tools_wts = [r_dict[str(item)] for item in top_k_wts.indices.numpy()[0]  if item not in [0, \"0\"]]\n",
    "\n",
    "    c_tools = [r_dict[str(item)] for item in compatible_tools[str(f_dict[last_tool_name])]]\n",
    "\n",
    "    pred_intersection = list(set(pred_tools).intersection(set(c_tools)))\n",
    "    prd_te_prec = len(pred_intersection) / float(n_topk_ind)\n",
    "\n",
    "    print(\"Tool sequence: {}\".format([r_dict[str(item)] for item in t_ip[label_pos]]))\n",
    "    print()\n",
    "    print(\"Compatible true tools: {}, size: {}\".format(c_tools, len(c_tools)))\n",
    "    print()\n",
    "    print(\"Predicted top {} tools: {}\".format(n_topk_ind, pred_tools))\n",
    "    print()\n",
    "    print(\"Predicted precision: {}\".format(prd_te_prec))\n",
    "    print()\n",
    "    print(\"Correctly predicted tools: {}\".format(pred_intersection))\n",
    "    print()\n",
    "    print(\"Predicted top {} tools with weights: {}\".format(n_topk_ind, pred_tools_wts))\n",
    "    print()\n",
    "\n",
    "    #generated_attention(att_weights, i_names, f_dict, r_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78ae0ec4-023c-4e86-8f6e-c6b2d29c371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool sequence: ['DatamashTranspose', 'dropletutils']\n",
      "\n",
      "Compatible true tools: ['scanpy_read_10x', 'seurat_read10x', 'tp_head_tool', 'anndata_import', 'raceid_filtnormconf', 'Convert characters1', 'scanpy_cluster_reduce_dimension', 'scanpy_plot', 'raceid_main', 'seurat'], size: 10\n",
      "\n",
      "Predicted top 20 tools: ['raceid_main', 'scanpy_cluster_reduce_dimension', 'scanpy_read_10x', 'seurat_read10x', 'scanpy_plot', 'anndata_import', 'seurat', 'Convert characters1', 'tp_head_tool', 'raceid_filtnormconf', 'tp_cat', 'comp1', 'histogram_rpy', 'scanpy_run_pca', 'fasta_merge_files_and_filter_unique_sequences', 'dropletutils', 'taxonomy_krona_chart', 'Remove beginning1', 'scanpy_compute_graph', 'raceid_clustering']\n",
      "\n",
      "Predicted precision: 0.5\n",
      "\n",
      "Correctly predicted tools: ['scanpy_cluster_reduce_dimension', 'raceid_filtnormconf', 'seurat', 'seurat_read10x', 'scanpy_read_10x', 'Convert characters1', 'raceid_main', 'scanpy_plot', 'tp_head_tool', 'anndata_import']\n",
      "\n",
      "Predicted top 20 tools with weights: ['tp_head_tool', 'anndata_import', 'scanpy_plot', 'seurat', 'scanpy_cluster_reduce_dimension', 'tp_cat', 'raceid_filtnormconf', 'fasta_merge_files_and_filter_unique_sequences', 'datamash_transpose', 'taxonomy_krona_chart', 'compose_text_param', 'histogram_rpy', 'dropletutils', 'scanpy_run_pca', 'anndata_inspect', 'regex1', 'gmx_solvate', 'mz_to_sqlite', 'tp_grep_tool', 'tp_replace_in_column']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_custom_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f496caf-c8e4-4020-8cf9-82497377da20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96355901-8e56-4ff3-a5e8-7e21189d98d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
