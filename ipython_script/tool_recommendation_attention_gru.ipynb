{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool recommendation with Attention network \n",
    "## (Gated recurrent units Attention neural network with weighted cross-entropy loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import operator\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import h5py\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        self.units = units\n",
    "        super(BahdanauAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        return super().get_config().copy()\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "\n",
    "class ToolPredictionAttentionModel():\n",
    "  \n",
    "    def __init__(self, parameters):\n",
    "        self.embedding_size = int(parameters[\"embedding_size\"])\n",
    "        self.gru_units = int(parameters[\"gru_units\"])\n",
    "        self.max_len = parameters[\"max_len\"]\n",
    "        self.dimensions = parameters[\"dimensions\"]\n",
    "        self.learning_rate = parameters[\"learning_rate\"]\n",
    "        self.class_weights = parameters[\"class_weights\"]\n",
    "        self.spatial_dropout = parameters[\"spatial_dropout\"]\n",
    "        self.recurrent_dropout = parameters[\"recurrent_dropout\"]\n",
    "        self.dropout = parameters[\"dropout\"]\n",
    "        \n",
    "    def weighted_loss(self, class_weights):\n",
    "        \"\"\"\n",
    "        Create a weighted loss function. Penalise the misclassification\n",
    "        of classes more with the higher usage\n",
    "        \"\"\"\n",
    "        weight_values = list(class_weights.values())\n",
    "\n",
    "        def weighted_binary_crossentropy(y_true, y_pred):\n",
    "            # add another dimension to compute dot product\n",
    "            expanded_weights = tf.keras.backend.expand_dims(weight_values, axis=-1)\n",
    "            return tf.keras.backend.dot(tf.keras.backend.binary_crossentropy(y_true, y_pred), expanded_weights)\n",
    "        return weighted_binary_crossentropy\n",
    "\n",
    "    def create_model(self):\n",
    "        sequence_input = tf.keras.layers.Input(shape=(self.max_len,), dtype='int32')\n",
    "        embedded_sequences = tf.keras.layers.Embedding(self.dimensions, self.embedding_size, input_length=self.max_len, mask_zero=True)(sequence_input)\n",
    "        embedded_sequences = tf.keras.layers.SpatialDropout1D(self.spatial_dropout)(embedded_sequences)\n",
    "        gru_1 = tf.keras.layers.GRU(self.gru_units,\n",
    "            return_sequences=True,\n",
    "            return_state=False,\n",
    "            activation='elu',\n",
    "            recurrent_dropout=self.recurrent_dropout\n",
    "        )\n",
    "        gru_2 = tf.keras.layers.GRU(self.gru_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            activation='elu',\n",
    "            recurrent_dropout=self.recurrent_dropout\n",
    "        )\n",
    "        gru_output = gru_1(embedded_sequences)\n",
    "        gru_output = tf.keras.layers.Dropout(self.dropout)(gru_output)\n",
    "        gru_output, gru_hidden = gru_2(gru_output)\n",
    "        attention = BahdanauAttention(self.gru_units)\n",
    "        context_vector, attention_weights = attention(gru_hidden, gru_output)\n",
    "        dropout = tf.keras.layers.Dropout(self.dropout)(context_vector)\n",
    "        output = tf.keras.layers.Dense(self.dimensions, activation='sigmoid')(dropout)\n",
    "        model = tf.keras.Model(inputs=sequence_input, outputs=output)\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.RMSprop(learning_rate=self.learning_rate),\n",
    "            loss=self.weighted_loss(self.class_weights),\n",
    "        )\n",
    "        return model\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    trained_model = h5py.File(model_path, 'r')\n",
    "    dictionary = json.loads(trained_model.get('data_dictionary').value)\n",
    "    best_parameters = json.loads(trained_model.get('parameters').value)\n",
    "    compatible_tools = json.loads(trained_model.get('compatible_tools').value)\n",
    "    reverse_dictionary = dict((str(v), k) for k, v in dictionary.items())\n",
    "    new_model = ToolPredictionAttentionModel(best_parameters).create_model()\n",
    "    new_model.load_weights(model_path)\n",
    "    return dictionary, reverse_dictionary, best_parameters, compatible_tools, new_model\n",
    "\n",
    "\n",
    "model_path = \"data/tool_recommendation_attention_model.hdf5\"\n",
    "dictionary, reverse_dictionary, best_parameters, compatible_tools, new_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpack trained model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'term_id_vs_term_name', '2': 'naive_variant_caller', '3': 'rseqc_infer_experiment', '4': 'macs2_bdgcmp', '5': 'rseqc_inner_distance', '6': 'CONVERTER_bed_to_bgzip_0', '7': 'gatk2_variant_annotator', '8': 'EMBOSS: fuzzpro38', '9': 'bismark_bowtie2', '10': 'samtools_rmdup', '11': 'msconvert3_raw', '12': 'tp_multijoin_tool', '13': 'samtools_sort', '14': 'ctb_remIons', '15': 'gff2bed1', '16': 'secretbt2test', '17': 'iuc_pear', '18': 'Count1', '19': 'tophat2', '20': 'MSGFPlusAdapter', '21': 'bamFilter', '22': 'bedtools_mergebed', '23': 'vcftools_merge', '24': 'sam_merge2', '25': 'freebayes', '26': 'cshl_cut_tool', '27': 'bam_to_sam', '28': 'flexbar_split_RR_bcs', '29': 'rgPicardMarkDups', '30': 'macs2_callpeak', '31': 'CONVERTER_gff_to_bed_0', '32': 'deeptools_bamCompare', '33': 'antismash', '34': 'gtf_filter_by_attribute_values_list', '35': 'tp_find_and_replace', '36': 'MzTabExporter', '37': 'bg_uniq', '38': 'cshl_fastq_to_fasta', '39': 'gatk2_indel_realigner', '40': 'tp_split_on_column', '41': 'samtools_flagstat', '42': 'EMBOSS: fuzztran39', '43': 'picard_ReorderSam', '44': 'cshl_word_list_grep', '45': 'Show beginning1', '46': 'FeatureFinderMultiplex', '47': 'Filter1', '48': 'vcftools_isec', '49': 'cshl_fastq_quality_filter', '50': 'remove_tail.py', '51': 'DatamashOps', '52': 'openms_id_file_converter', '53': 'methtools_filter', '54': 'Summary_Statistics1', '55': 'Grouping1', '56': 'extract_bcs.py', '57': 'fasta2tab', '58': 'cshl_fastx_nucleotides_distribution', '59': 'ncbi_tblastn_wrapper', '60': 'Extract_features1', '61': 'random_lines1', '62': 'deseq2_single', '63': 'IDFilter', '64': 'ncbi_blastn_wrapper', '65': 'EMBOSS: transeq101', '66': 'fasta_filter_by_length', '67': 'cshl_grep_tool', '68': 'stringtie', '69': 'deeptools_correctGCBias', '70': 'proteomics_search_protein_prophet_1', '71': 'get_flanks1', '72': 'ctb_compound_convert', '73': 'CONVERTER_interval_to_bgzip_0', '74': 'seq_filter_by_mapping', '75': 'hgv_david', '76': 'gops_subtract_1', '77': 'picard_EstimateLibraryComplexity', '78': 'ctb_simsearch', '79': 'bwa_mem', '80': 'ctb_pubchem_download_as_smiles', '81': 'vcfallelicprimitives', '82': 'cummerbund_to_cuffdiff', '83': 'EMBOSS: newseq59', '84': 'bedtools_bamtofastq', '85': 'samtool_filter2', '86': 'prokaryotic_ncbi_submission', '87': 'PicardInsertSize', '88': 'augustus', '89': 'EMBOSS: geecee41', '90': 'EMBOSS: water107', '91': 'filter_bed_on_splice_junctions', '92': 'ConsensusID', '93': 'Show tail1', '94': 'subtract_query1', '95': 'vcffilter', '96': 'FalseDiscoveryRate', '97': 'ctb_change_title', '98': 'trimmomatic', '99': 'tp_head_tool', '100': 'blastxml_to_top_descr', '101': 'picard_CollectInsertSizeMetrics', '102': 'megablast_xml_parser', '103': 'bedtools_bamtobed', '104': 'picard_ValidateSamFile', '105': 'rseqc_bam2wig', '106': 'gatk2_variant_recalibrator', '107': 'cshl_awk_tool', '108': 'bismark_bowtie', '109': 'bedtools_unionbedgraph', '110': 'r_correlation_matrix', '111': 'dt_profiler', '112': 'peakcalling_macs', '113': 'sed_stream_editor', '114': 'EMBOSS: shuffleseq87', '115': 'XTandemAdapter', '116': 'bedtools_intersectbed', '117': 'wolf_psort', '118': 'get_subontology_from', '119': 'fastqc', '120': 'cuffcompare', '121': 'ProteinQuantifier', '122': 'cshl_sort_header', '123': 'glimmer_build-icm', '124': 'fasta_compute_length', '125': 'gatk2_reduce_reads', '126': 'wc_gnu', '127': 'vt_normalize', '128': 'blast2go', '129': 'tp_sorted_uniq', '130': 'bowtie2', '131': 'samtools_stats', '132': 'tp_replace_in_line', '133': 'flexbardsc', '134': 'XY_Plot_1', '135': 'gops_intersect_1', '136': 'extract_aln_ends.py', '137': 'deeptools_bamCoverage', '138': 'meme_meme', '139': 'proteomics_search_peptide_prophet_1', '140': 'fastq_to_tabular', '141': 'ncbi_blastp_wrapper', '142': 'picard_ARRG', '143': 'cshl_uniq_tool', '144': 'cshl_fastx_trimmer', '145': 'scaffold2fasta', '146': 'heatmapper', '147': 'htseq-count', '148': 'tp_sed_tool', '149': 'tmhmm2', '150': 'deeptools_heatmapper', '151': 'aragorn_trna', '152': 'gops_coverage_1', '153': 'Extract genomic DNA 1', '154': 'bedtools_intersectbed_bam', '155': 'Add_a_column1', '156': 'tp_cut_tool', '157': 'hisat2', '158': 'smooth_running_window', '159': 'picard_CASM', '160': 'fragmenter', '161': 'Cut1', '162': 'cshl_sed_tool', '163': 'picard_BamIndexStats', '164': 'fastq_to_fasta_python', '165': 'gff_to_sequence', '166': 'gatk2_print_reads', '167': 'deeptools_plot_heatmap', '168': 'mergeCols1', '169': 'snpSift_filter', '170': 'bedtools_bedtobam', '171': 'IDMerger', '172': 'FileMerger', '173': 'Grep1', '174': 'rmcontamination', '175': 'PeptideIndexer', '176': 'eukaryotic_ncbi_submission', '177': 'tp_unfold_column_tool', '178': 'ngsutils_bam_filter', '179': 'cufflinks', '180': 'Convert characters1', '181': 'deseq2', '182': 'Datamash', '183': 'predict_pipeline', '184': 'tp_tac', '185': 'bgchem_fragment_merger', '186': 'blastxml_to_tabular', '187': 'tab2fasta', '188': 'sam2interval', '189': 'flexbar', '190': 'bedtools_intersectBed', '191': 'allele_counts_1', '192': 'Paste1', '193': 'sam_to_bam', '194': 'deeptools_bamCorrelate', '195': 'coords2clnt.py', '196': 'snpEff', '197': 'gatk2_variant_apply_recalibration', '198': 'comp1', '199': 'cummeRbund', '200': 'sample_seqs', '201': 'deeptools_computeGCBias', '202': 'addValue', '203': 'convert_bc_to_binary_RY.py', '204': 'methtools_calling', '205': 'flexbar_split_RYYR_bcs', '206': 'Remove_ending', '207': 'ncbi_rpsblast_wrapper', '208': 'cshl_find_and_replace', '209': 'hisat', '210': 'fastq_quality_trimmer', '211': 'seq_filter_by_id', '212': 'gtf2bedgraph', '213': 'DatamashTranspose', '214': 'silac_analyzer', '215': 'ncbi_makeblastdb', '216': 'bedtools_coveragebed', '217': 'openms_id_mapper', '218': 'flexbar_no_split', '219': 'cshl_awk_replace_in_column', '220': 'cat1', '221': 'wig_to_bigWig', '222': 'cshl_fastx_artifacts_filter', '223': 'join1', '224': 'rm_spurious_events.py', '225': 'Psortb', '226': 'deeptools_compute_matrix', '227': 'methtools_dmr', '228': 'bam2wig', '229': 'tp_replace_in_column', '230': 'HighResPrecursorMassCorrector', '231': 'ctb_chemfp_mol2fps', '232': 'cshl_fastq_quality_boxplot', '233': 'openms_protein_quantifier', '234': 'heatmapper_deepTools', '235': 'FidoAdapter', '236': 'tp_sort_header_tool', '237': 'cuffdiff', '238': 'CONVERTER_interval_to_bedstrict_0', '239': 'deeptools_profiler', '240': 'snpSift_annotate', '241': 'interproscan', '242': 'bedtools_genomecoveragebed', '243': 'bedtools_genomecoveragebed_bedgraph', '244': 'tp_awk_tool', '245': 'merge_pcr_duplicates.py', '246': 'picard_MarkDuplicates', '247': 'IDPosteriorErrorProbability', '248': 'infernal_cmsearch', '249': 'Remove beginning1', '250': 'picard_FixMateInformation', '251': 'glimmer_knowlegde-based', '252': 'picard_NormalizeFasta', '253': 'modencode_peakcalling_macs2', '254': 'deeptools_bamFingerprint', '255': 'fastq_join', '256': 'gatk2_base_recalibrator', '257': 'samtools_mpileup', '258': 'term_id_vs_term_def', '259': 'gops_join_1', '260': 'deeptools_computeMatrix', '261': 'methtools_destrand', '262': 'bedtools_multiintersectbed', '263': 'tp_cat', '264': 'cshl_fastx_quality_statistics', '265': 'picard_SamToFastq', '266': 'piranha', '267': 'cshl_multijoin', '268': 'gatk2_haplotype_caller', '269': 'barchart_gnuplot', '270': 'tp_easyjoin_tool', '271': 'signalp3', '272': 'cor2', '273': 'p_clip_peaks', '274': 'IDMapper', '275': 'IDConflictResolver', '276': 'regex_replace', '277': 'peakcalling_macs14', '278': 'bamCoverage_deepTools', '279': 'deeptools_bam_coverage', '280': 'ssake', '281': 'cshl_fastx_clipper', '282': 'sort1', '283': 'ctb_filter', '284': 'CONVERTER_bed_gff_or_vcf_to_bigwig_0', '285': 'gatk2_realigner_target_creator', '286': 'cuffmerge', '287': 'bcftools_view', '288': 'bed2gff1', '289': 'CONVERTER_interval_to_bed_0', '290': 'tophat', '291': 'tp_tail_tool', '292': 'htseq_count', '293': 'proteomics_search_tandem_1', '294': 'rsem_calculate_expression', '295': 'deeptools_bigwigCompare', '296': 'FileFilter', '297': 'bedtools_sortbed', '298': 'blockbuster', '299': 'ctb_online_data_fetch', '300': 'CONVERTER_bedgraph_to_bigwig', '301': 'bedtools_coveragebed_counts', '302': 'trim_galore', '303': 'blockclust', '304': 'computeMatrix', '305': 'sam_bw_filter', '306': 'fastq_groomer', '307': 'bwa_wrapper', '308': 'gatk2_variant_select', '309': 'methtools_plot'}\n"
     ]
    }
   ],
   "source": [
    "print(reverse_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recommendations(tool_sequence, labels, topk=20, max_seq_len=25):\n",
    "    tl_seq = tool_sequence.split(\",\")\n",
    "    last_tool_name = reverse_dictionary[str(tl_seq[-1])]\n",
    "    sample = np.zeros(max_seq_len)\n",
    "    for idx, tool_id in enumerate(tl_seq):\n",
    "        sample[idx] = int(tool_id)\n",
    "    sample_reshaped = np.reshape(sample, (1, max_seq_len))\n",
    "    tool_sequence_names = [reverse_dictionary[str(tool_pos)] for tool_pos in tool_sequence.split(\",\")]\n",
    "    # predict next tools for a test path\n",
    "    prediction = new_model.predict(sample_reshaped, verbose=0)\n",
    "    class_weights = best_parameters[\"class_weights\"]\n",
    "    weight_val = list(class_weights.values())\n",
    "    weight_val = np.reshape(weight_val, (len(weight_val),))\n",
    "    prediction = np.reshape(prediction, (prediction.shape[1],))\n",
    "    #prediction = prediction * weight_val\n",
    "    prediction = prediction / float(np.max(prediction))\n",
    "    prediction_pos = np.argsort(prediction, axis=-1)\n",
    "    # get topk prediction\n",
    "    topk_prediction_pos = prediction_pos[-topk:]\n",
    "    topk_prediction_pos = [item for item in topk_prediction_pos if item != 0]\n",
    "    topk_prediction_val = [int(prediction[pos] * 100) for pos in topk_prediction_pos]\n",
    "    # read tool names using reverse dictionary\n",
    "    pred_tool_ids = [reverse_dictionary[str(tool_pos)] for tool_pos in topk_prediction_pos]\n",
    "    pred_tool_ids_sorted = dict()\n",
    "    for (tool_pos, tool_pred_val) in zip(topk_prediction_pos, topk_prediction_val):\n",
    "        tool_name = reverse_dictionary[str(tool_pos)]\n",
    "        pred_tool_ids_sorted[tool_name] = tool_pred_val\n",
    "    pred_tool_ids_sorted = dict(sorted(pred_tool_ids_sorted.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    ids_tools = dict()\n",
    "    keys = list(pred_tool_ids_sorted.keys())\n",
    "    tool_seq_name = \",\".join(tool_sequence_names)\n",
    "    print(\"Current tool sequence: \")\n",
    "    print()\n",
    "    print(tool_seq_name)\n",
    "    print()\n",
    "    print(\"Recommended tools for the tool sequence '%s' with their scores in decreasing order:\" % tool_seq_name)\n",
    "    print()\n",
    "    for i in pred_tool_ids_sorted:\n",
    "        print(i + \"(\" + str(pred_tool_ids_sorted[i]) + \"%)\")\n",
    "    for key in pred_tool_ids_sorted:\n",
    "        ids_tools[key] = dictionary[key]\n",
    "    print()\n",
    "    print(\"Tool ids:\")\n",
    "    print()\n",
    "    for i in ids_tools:\n",
    "        print(i + \"(\" + str(ids_tools[i]) + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indices of tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current tool sequence: \n",
      "\n",
      "naive_variant_caller\n",
      "\n",
      "Recommended tools for the tool sequence 'naive_variant_caller' with their scores in decreasing order:\n",
      "\n",
      "flexbar_split_RR_bcs(100%)\n",
      "deeptools_profiler(96%)\n",
      "eukaryotic_ncbi_submission(94%)\n",
      "tp_awk_tool(92%)\n",
      "Remove_ending(90%)\n",
      "deeptools_correctGCBias(90%)\n",
      "MSGFPlusAdapter(89%)\n",
      "DatamashTranspose(88%)\n",
      "deeptools_bigwigCompare(86%)\n",
      "gatk2_variant_select(85%)\n",
      "deeptools_computeGCBias(83%)\n",
      "Datamash(79%)\n",
      "silac_analyzer(79%)\n",
      "bam2wig(79%)\n",
      "cshl_cut_tool(78%)\n",
      "bamCoverage_deepTools(77%)\n",
      "deseq2_single(77%)\n",
      "cshl_awk_replace_in_column(76%)\n",
      "msconvert3_raw(74%)\n",
      "heatmapper(70%)\n",
      "\n",
      "Tool ids:\n",
      "\n",
      "flexbar_split_RR_bcs(28)\n",
      "deeptools_profiler(239)\n",
      "eukaryotic_ncbi_submission(176)\n",
      "tp_awk_tool(244)\n",
      "Remove_ending(206)\n",
      "deeptools_correctGCBias(69)\n",
      "MSGFPlusAdapter(20)\n",
      "DatamashTranspose(213)\n",
      "deeptools_bigwigCompare(295)\n",
      "gatk2_variant_select(308)\n",
      "deeptools_computeGCBias(201)\n",
      "Datamash(182)\n",
      "silac_analyzer(214)\n",
      "bam2wig(228)\n",
      "cshl_cut_tool(26)\n",
      "bamCoverage_deepTools(278)\n",
      "deseq2_single(62)\n",
      "cshl_awk_replace_in_column(219)\n",
      "msconvert3_raw(11)\n",
      "heatmapper(146)\n"
     ]
    }
   ],
   "source": [
    "topk = 20 # set the maximum number of recommendations\n",
    "tool_seq = \"2\" # give tools ids in a sequence and see the recommendations. To know all the tool ids, \n",
    "                     # please print the variable 'reverse_dictionary'\n",
    "compute_recommendations(tool_seq, \"\", topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 25)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 25, 132)           40920     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 25, 132)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 25, 122)           93696     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25, 122)           0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  [(None, 25, 122), (None,  90036     \n",
      "_________________________________________________________________\n",
      "bahdanau_attention_1 (Bahdan ((None, 122), (None, 25,  30135     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 122)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 310)               38130     \n",
      "=================================================================\n",
      "Total params: 292,917\n",
      "Trainable params: 292,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(new_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_size': 132, 'gru_units': 122, 'spatial1d_dropout': 0.4, 'dropout': 0.35000000000000003, 'recurrent_dropout': 0.35000000000000003, 'learning_rate': 0.03692115994017956, 'tuner/epochs': 1, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0, 'batch_size': 32, 'max_len': 25, 'dimensions': 310, 'class_weights': {'0': 0.0, '1': 0.09543005443725577, '2': 1.6582978932139152, '3': 4.812256047599217, '4': 0.6960840387669792, '5': 0.13845555899307133, '6': 1.2530738801573276, '7': 0.09538827675467865, '8': 0.07964582277129585, '9': 2.36302973908641, '10': 5.992613886364503, '11': 0.0, '12': 3.3953636085831604, '13': 4.556972389179466, '14': 0.07041739104367695, '15': 2.163323025660538, '16': 0.07250647687303469, '17': 0.5097738248193585, '18': 3.747675549429567, '19': 4.893910221874146, '20': 0.0, '21': 5.2482257831848935, '22': 4.387828804608451, '23': 2.3826786024540727, '24': 5.6680003185450945, '25': 6.576772652723754, '26': 0.0, '27': 0.0, '28': 0.0, '29': 0.5889135741457597, '30': 5.883043798153562, '31': 3.0892559462316123, '32': 0.07189469179761168, '33': 3.487433480173297, '34': 1.2623529373962634, '35': 5.382251053396031, '36': 2.1856234256723175, '37': 2.802362331505732, '38': 5.104125637183595, '39': 0.6875761360691492, '40': 1.683676062828553, '41': 5.755483261770645, '42': 0.0, '43': 0.09531073434962559, '44': 0.07189469179761168, '45': 4.566142639960839, '46': 5.102553377787591, '47': 7.0405799283399615, '48': 0.5534520941998734, '49': 4.500920164614292, '50': 0.6878727954132038, '51': 0.061612021235966506, '52': 0.0, '53': 0.10258264394232028, '54': 3.856428173309885, '55': 4.710430790975013, '56': 0.38668123051024755, '57': 6.190901061884645, '58': 0.09187671949238563, '59': 2.285273209338971, '60': 2.234375470401864, '61': 2.1662269660607643, '62': 0.0, '63': 4.8283283891949615, '64': 5.631504993955934, '65': 0.9141247037279912, '66': 5.767059074749979, '67': 0.026003879333510976, '68': 5.345744330744355, '69': 0.0, '70': 0.0869905767733068, '71': 0.0, '72': 0.09531017980432493, '73': 0.016930742674575377, '74': 0.38600688549788165, '75': 1.018324172551051, '76': 1.5625746771441749, '77': 0.5196069448607583, '78': 0.3291822433584368, '79': 7.360040357734192, '80': 0.1823215567939546, '81': 5.913932166319434, '82': 1.3535022515442852, '83': 0.39796300423345954, '84': 4.116595171156921, '85': 5.8328269641651795, '86': 0.0, '87': 0.8715893263269244, '88': 4.26323736893777, '89': 1.2584609896100056, '90': 0.41207446477734766, '91': 0.09531017980432493, '92': 3.0032081216359656, '93': 0.0, '94': 0.1879510232386989, '95': 0.07250647687303469, '96': 5.5060777871737265, '97': 0.07041739104367695, '98': 7.422373700986824, '99': 4.220534985284344, '100': 4.586322377523295, '101': 2.451005098112319, '102': 0.3241120995875124, '103': 3.589797968190993, '104': 1.5795052961728004, '105': 3.587600554538827, '106': 0.09530912525831431, '107': 0.09531017980432493, '108': 1.479424008472176, '109': 1.1169614287908518, '110': 0.0, '111': 0.0, '112': 3.59562485251039, '113': 0.0, '114': 0.06263988862502112, '115': 4.878760174427442, '116': 6.73240933592858, '117': 1.606719464801262, '118': 0.09543005443725577, '119': 8.668715028378008, '120': 0.6695903903040974, '121': 5.374815302782456, '122': 0.07250647687303469, '123': 0.09531017980432493, '124': 3.0007198150650303, '125': 0.0, '126': 4.440851943402857, '127': 0.2527023535557542, '128': 1.5018192446243235, '129': 4.123490009141191, '130': 7.13966033596492, '131': 4.695671971973471, '132': 5.330374911417734, '133': 0.0, '134': 2.0268152750688944, '135': 3.6682516181767437, '136': 0.5368147223842971, '137': 0.09532353426060833, '138': 3.2457648765922755, '139': 0.06399421365412633, '140': 1.9168309432747128, '141': 5.185388581262361, '142': 0.09531017980432493, '143': 0.07250647687303469, '144': 4.370482989692134, '145': 0.0, '146': 0.0, '147': 0.0, '148': 3.9202774825001394, '149': 2.220410534624088, '150': 0.0, '151': 1.9296225475826647, '152': 0.34380222790464565, '153': 4.146814615224232, '154': 0.026118307998642735, '155': 5.888814776503156, '156': 6.077795136866647, '157': 6.77337540620297, '158': 0.09530406160379044, '159': 2.7111174575911785, '160': 0.09531017980432493, '161': 7.160087138220143, '162': 0.0, '163': 2.8087371203020917, '164': 6.509065023535706, '165': 0.09531017980432493, '166': 0.0953052070646881, '167': 6.258042318888258, '168': 4.167255167580128, '169': 4.432006566978902, '170': 4.382679657408116, '171': 3.2681268641517134, '172': 0.3668217386599276, '173': 5.588244857534695, '174': 0.0, '175': 4.993573370845278, '176': 0.0, '177': 0.16243582304452936, '178': 5.793976976269424, '179': 5.249888185668796, '180': 3.7509861930519683, '181': 6.278333789302737, '182': 0.0, '183': 0.08976817851796072, '184': 0.09531017980432493, '185': 0.0, '186': 0.45622654074899477, '187': 5.586561781205797, '188': 0.4054651081081644, '189': 0.07250647687303469, '190': 0.0, '191': 0.5089603291852106, '192': 2.9900494905861095, '193': 3.8678880399081907, '194': 0.0, '195': 0.6600210747001517, '196': 5.65510384781625, '197': 0.0, '198': 5.799092654460526, '199': 3.0794785217240763, '200': 0.1153108445307964, '201': 0.0, '202': 6.134101924823247, '203': 0.0, '204': 0.9666204988181899, '205': 0.0, '206': 0.0, '207': 1.5818836937517387, '208': 0.07964582277129585, '209': 0.0, '210': 2.282374674422305, '211': 2.651965442452904, '212': 0.384289751049462, '213': 0.0, '214': 0.0, '215': 4.298725613384298, '216': 4.206458375495826, '217': 0.0, '218': 0.6878727954132038, '219': 0.0, '220': 6.446513155404975, '221': 5.479313217732502, '222': 1.8836586138183606, '223': 5.785395391705502, '224': 0.6600210747001517, '225': 0.09048175077058784, '226': 6.130624010985935, '227': 0.6418784174504478, '228': 0.0, '229': 3.709639438928503, '230': 1.31610213587424, '231': 0.22314355131420976, '232': 0.6712322429062169, '233': 0.0, '234': 0.0, '235': 5.631658856850509, '236': 6.538477441630863, '237': 3.698178191785774, '238': 4.502839461540633, '239': 0.0, '240': 3.988520976400871, '241': 3.5483850691681953, '242': 4.317180373922666, '243': 0.0, '244': 0.0, '245': 0.6600210747001517, '246': 5.78484241624876, '247': 4.38806310770465, '248': 5.834387317169895, '249': 5.6889911384039635, '250': 0.6018501587539669, '251': 0.44941864223599143, '252': 2.4336133554004498, '253': 0.0, '254': 0.0, '255': 5.225949787277793, '256': 0.41178132541076307, '257': 4.6549122778829055, '258': 0.0, '259': 3.7214488425624106, '260': 0.0, '261': 0.06805043152989372, '262': 1.8989670255555637, '263': 5.26830770223046, '264': 0.38750290259636944, '265': 1.4079816206942064, '266': 2.4045927770886624, '267': 0.0, '268': 2.07093447397118, '269': 0.44291052841248557, '270': 6.297845696992248, '271': 0.6280071025232983, '272': 1.650222229444567, '273': 0.09359915319644818, '274': 4.271610051538416, '275': 4.071363882392451, '276': 1.4393338223204117, '277': 0.0, '278': 0.0, '279': 6.97617687621502, '280': 2.1056058939006714, '281': 2.0360119837525, '282': 4.568367283876591, '283': 0.0, '284': 3.490589678926948, '285': 2.9626925471243615, '286': 3.6149637711637683, '287': 0.02803959057123678, '288': 1.4713061761506316, '289': 4.925770268699728, '290': 0.0, '291': 4.604344316451709, '292': 6.562585326657728, '293': 0.5994148283307562, '294': 0.1359871659931982, '295': 0.0, '296': 5.118858189393999, '297': 4.490221318991273, '298': 0.0, '299': 1.7787480381679142, '300': 4.381192953883603, '301': 0.0, '302': 6.982862751468942, '303': 0.39373655675765357, '304': 0.0, '305': 1.2679033691330028, '306': 6.370256557121318, '307': 0.09530577070369572, '308': 0.0, '309': 0.09473615144520271}}\n"
     ]
    }
   ],
   "source": [
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
