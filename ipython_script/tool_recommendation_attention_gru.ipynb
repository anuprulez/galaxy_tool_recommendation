{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool recommendation with Attention network \n",
    "## (Gated recurrent units Attention neural network with weighted cross-entropy loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import operator\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import h5py\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        self.units = units\n",
    "        super(BahdanauAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        return super().get_config().copy()\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "\n",
    "class ToolPredictionAttentionModel():\n",
    "  \n",
    "    def __init__(self, parameters):\n",
    "        self.embedding_size = int(parameters[\"embedding_size\"])\n",
    "        self.gru_units = int(parameters[\"units\"])\n",
    "        self.max_len = parameters[\"max_len\"]\n",
    "        self.dimensions = parameters[\"dimensions\"]\n",
    "        self.learning_rate = parameters[\"learning_rate\"]\n",
    "        self.class_weights = parameters[\"class_weights\"]\n",
    "        self.spatial_dropout = parameters[\"spatial_dropout\"]\n",
    "        self.recurrent_dropout = parameters[\"recurrent_dropout\"]\n",
    "        self.dropout = parameters[\"dropout\"]\n",
    "        \n",
    "    def weighted_loss(self, class_weights):\n",
    "        \"\"\"\n",
    "        Create a weighted loss function. Penalise the misclassification\n",
    "        of classes more with the higher usage\n",
    "        \"\"\"\n",
    "        weight_values = list(class_weights.values())\n",
    "\n",
    "        def weighted_binary_crossentropy(y_true, y_pred):\n",
    "            # add another dimension to compute dot product\n",
    "            expanded_weights = tf.keras.backend.expand_dims(weight_values, axis=-1)\n",
    "            return tf.keras.backend.dot(tf.keras.backend.binary_crossentropy(y_true, y_pred), expanded_weights)\n",
    "        return weighted_binary_crossentropy\n",
    "\n",
    "    def create_model(self):\n",
    "        sequence_input = tf.keras.layers.Input(shape=(self.max_len,), dtype='int32')\n",
    "        embedded_sequences = tf.keras.layers.Embedding(self.dimensions, self.embedding_size, input_length=self.max_len, mask_zero=True)(sequence_input)\n",
    "        embedded_sequences = tf.keras.layers.SpatialDropout1D(self.spatial_dropout)(embedded_sequences)\n",
    "        gru_1 = tf.keras.layers.GRU(self.gru_units,\n",
    "            return_sequences=True,\n",
    "            return_state=False,\n",
    "            activation='elu',\n",
    "            recurrent_dropout=self.recurrent_dropout\n",
    "        )\n",
    "        gru_2 = tf.keras.layers.GRU(self.gru_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            activation='elu',\n",
    "            recurrent_dropout=self.recurrent_dropout\n",
    "        )\n",
    "        gru_output = gru_1(embedded_sequences)\n",
    "        gru_output = tf.keras.layers.Dropout(self.dropout)(gru_output)\n",
    "        gru_output, gru_hidden = gru_2(gru_output)\n",
    "        attention = BahdanauAttention(self.gru_units)\n",
    "        context_vector, attention_weights = attention(gru_hidden, gru_output)\n",
    "        dropout = tf.keras.layers.Dropout(self.dropout)(context_vector)\n",
    "        output = tf.keras.layers.Dense(self.dimensions, activation='sigmoid')(dropout)\n",
    "        model = tf.keras.Model(inputs=sequence_input, outputs=output)\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.RMSprop(learning_rate=self.learning_rate),\n",
    "            loss=self.weighted_loss(self.class_weights),\n",
    "        )\n",
    "        return model\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    trained_model = h5py.File(model_path, 'r')\n",
    "    dictionary = json.loads(trained_model.get('data_dictionary').value)\n",
    "    best_parameters = json.loads(trained_model.get('parameters').value)\n",
    "    compatible_tools = json.loads(trained_model.get('compatible_tools').value)\n",
    "    reverse_dictionary = dict((str(v), k) for k, v in dictionary.items())\n",
    "    new_model = ToolPredictionAttentionModel(best_parameters).create_model()\n",
    "    new_model.load_weights(model_path)\n",
    "    return dictionary, reverse_dictionary, class_weights, best_parameters, compatible_tools, new_model\n",
    "\n",
    "\n",
    "model_path = \"data/tool_recommendation_attention_model.hdf5\"\n",
    "dictionary, reverse_dictionary, class_weights, best_parameters, compatible_tools, new_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpack trained model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'gops_intersect_1', '2': 'coords2clnt.py', '3': 'blockbuster', '4': 'Add_a_column1', '5': 'blockclust', '6': 'Datamash', '7': 'methtools_calling', '8': 'methtools_dmr', '9': 'ctb_simsearch', '10': 'trim_galore', '11': 'deeptools_correctGCBias', '12': 'sed_stream_editor', '13': 'rgPicardMarkDups', '14': 'fasta_filter_by_length', '15': 'seq_filter_by_id', '16': 'deeptools_bamCoverage', '17': 'piranha', '18': 'vcftools_merge', '19': 'ssake', '20': 'cuffcompare', '21': 'flexbar_split_RYYR_bcs', '22': 'tp_head_tool', '23': 'r_correlation_matrix', '24': 'wc_gnu', '25': 'cshl_awk_replace_in_column', '26': 'ncbi_blastp_wrapper', '27': 'stringtie', '28': 'mergeCols1', '29': 'cshl_fastq_quality_filter', '30': 'Show tail1', '31': 'CONVERTER_interval_to_bedstrict_0', '32': 'term_id_vs_term_name', '33': 'aragorn_trna', '34': 'filter_bed_on_splice_junctions', '35': 'subtract_query1', '36': 'fastq_groomer', '37': 'cuffdiff', '38': 'tp_sed_tool', '39': 'Grouping1', '40': 'convert_bc_to_binary_RY.py', '41': 'ngsutils_bam_filter', '42': 'deeptools_bamFingerprint', '43': 'vcffilter', '44': 'ctb_remIons', '45': 'term_id_vs_term_def', '46': 'ctb_online_data_fetch', '47': 'MzTabExporter', '48': 'bed2gff1', '49': 'deeptools_bam_coverage', '50': 'ncbi_rpsblast_wrapper', '51': 'picard_CASM', '52': 'tophat', '53': 'picard_CollectInsertSizeMetrics', '54': 'tp_sort_header_tool', '55': 'tp_multijoin_tool', '56': 'ctb_pubchem_download_as_smiles', '57': 'wig_to_bigWig', '58': 'secretbt2test', '59': 'extract_aln_ends.py', '60': 'cshl_sort_header', '61': 'EMBOSS: fuzztran39', '62': 'deeptools_bamCompare', '63': 'CONVERTER_interval_to_bed_0', '64': 'methtools_plot', '65': 'gatk2_indel_realigner', '66': 'bam_to_sam', '67': 'IDConflictResolver', '68': 'glimmer_knowlegde-based', '69': 'signalp3', '70': 'fastqc', '71': 'samtools_sort', '72': 'tp_awk_tool', '73': 'deeptools_bigwigCompare', '74': 'Count1', '75': 'tp_tail_tool', '76': 'naive_variant_caller', '77': 'openms_id_file_converter', '78': 'FidoAdapter', '79': 'tab2fasta', '80': 'gatk2_variant_recalibrator', '81': 'ctb_compound_convert', '82': 'gatk2_variant_annotator', '83': 'peakcalling_macs', '84': 'FileMerger', '85': 'ctb_chemfp_mol2fps', '86': 'gatk2_base_recalibrator', '87': 'PeptideIndexer', '88': 'sam2interval', '89': 'rm_spurious_events.py', '90': 'bamFilter', '91': 'cshl_cut_tool', '92': 'fasta_compute_length', '93': 'MSGFPlusAdapter', '94': 'rseqc_inner_distance', '95': 'picard_SamToFastq', '96': 'random_lines1', '97': 'samtools_mpileup', '98': 'bwa_wrapper', '99': 'vcfallelicprimitives', '100': 'bismark_bowtie2', '101': 'heatmapper_deepTools', '102': 'EMBOSS: fuzzpro38', '103': 'snpEff', '104': 'picard_ARRG', '105': 'bg_uniq', '106': 'prokaryotic_ncbi_submission', '107': 'Paste1', '108': 'Grep1', '109': 'deseq2', '110': 'addValue', '111': 'get_flanks1', '112': 'gatk2_print_reads', '113': 'peakcalling_macs14', '114': 'picard_MarkDuplicates', '115': 'bedtools_intersectbed', '116': 'barchart_gnuplot', '117': 'tp_find_and_replace', '118': 'ncbi_blastn_wrapper', '119': 'rsem_calculate_expression', '120': 'bedtools_unionbedgraph', '121': 'fastq_to_fasta_python', '122': 'tp_tac', '123': 'cshl_sed_tool', '124': 'bedtools_bamtofastq', '125': 'msconvert3_raw', '126': 'cshl_awk_tool', '127': 'gff2bed1', '128': 'gtf_filter_by_attribute_values_list', '129': 'cshl_word_list_grep', '130': 'cshl_uniq_tool', '131': 'fastq_join', '132': 'tmhmm2', '133': 'flexbar', '134': 'picard_BamIndexStats', '135': 'blastxml_to_tabular', '136': 'tp_easyjoin_tool', '137': 'flexbar_no_split', '138': 'blastxml_to_top_descr', '139': 'infernal_cmsearch', '140': 'EMBOSS: shuffleseq87', '141': 'deeptools_compute_matrix', '142': 'gatk2_variant_apply_recalibration', '143': 'snpSift_filter', '144': 'Psortb', '145': 'cshl_fastx_clipper', '146': 'flexbar_split_RR_bcs', '147': 'hgv_david', '148': 'gops_join_1', '149': 'deeptools_bamCorrelate', '150': 'interproscan', '151': 'proteomics_search_peptide_prophet_1', '152': 'ctb_filter', '153': 'eukaryotic_ncbi_submission', '154': 'Filter1', '155': 'bedtools_multiintersectbed', '156': 'fasta2tab', '157': 'gff_to_sequence', '158': 'fastq_quality_trimmer', '159': 'heatmapper', '160': 'Cut1', '161': 'DatamashTranspose', '162': 'glimmer_build-icm', '163': 'EMBOSS: water107', '164': 'rseqc_infer_experiment', '165': 'XY_Plot_1', '166': 'rmcontamination', '167': 'augustus', '168': 'ncbi_makeblastdb', '169': 'ConsensusID', '170': 'tp_replace_in_line', '171': 'proteomics_search_protein_prophet_1', '172': 'cshl_grep_tool', '173': 'Convert characters1', '174': 'samtools_rmdup', '175': 'dt_profiler', '176': 'HighResPrecursorMassCorrector', '177': 'seq_filter_by_mapping', '178': 'cor2', '179': 'bamCoverage_deepTools', '180': 'hisat2', '181': 'flexbardsc', '182': 'cummeRbund', '183': 'deeptools_computeGCBias', '184': 'sam_merge2', '185': 'proteomics_search_tandem_1', '186': 'picard_ReorderSam', '187': 'gops_subtract_1', '188': 'Remove_ending', '189': 'PicardInsertSize', '190': 'bedtools_bamtobed', '191': 'openms_id_mapper', '192': 'hisat', '193': 'megablast_xml_parser', '194': 'merge_pcr_duplicates.py', '195': 'macs2_callpeak', '196': 'picard_ValidateSamFile', '197': 'picard_FixMateInformation', '198': 'deeptools_computeMatrix', '199': 'deeptools_plot_heatmap', '200': 'ncbi_tblastn_wrapper', '201': 'EMBOSS: geecee41', '202': 'IDMerger', '203': 'ProteinQuantifier', '204': 'join1', '205': 'computeMatrix', '206': 'deeptools_heatmapper', '207': 'fragmenter', '208': 'blast2go', '209': 'gatk2_variant_select', '210': 'bedtools_coveragebed', '211': 'sample_seqs', '212': 'FileFilter', '213': 'cshl_fastq_quality_boxplot', '214': 'bedtools_intersectBed', '215': 'comp1', '216': 'ctb_change_title', '217': 'freebayes', '218': 'iuc_pear', '219': 'tp_sorted_uniq', '220': 'remove_tail.py', '221': 'IDMapper', '222': 'gatk2_reduce_reads', '223': 'bedtools_genomecoveragebed_bedgraph', '224': 'extract_bcs.py', '225': 'bgchem_fragment_merger', '226': 'modencode_peakcalling_macs2', '227': 'scaffold2fasta', '228': 'htseq_count', '229': 'tophat2', '230': 'bedtools_intersectbed_bam', '231': 'bedtools_bedtobam', '232': 'Extract_features1', '233': 'bcftools_view', '234': 'cshl_fastx_nucleotides_distribution', '235': 'Summary_Statistics1', '236': 'tp_cat', '237': 'bwa_mem', '238': 'FeatureFinderMultiplex', '239': 'IDFilter', '240': 'cuffmerge', '241': 'antismash', '242': 'Extract genomic DNA 1', '243': 'methtools_filter', '244': 'cshl_fastq_to_fasta', '245': 'allele_counts_1', '246': 'cshl_find_and_replace', '247': 'CONVERTER_bedgraph_to_bigwig', '248': 'gtf2bedgraph', '249': 'CONVERTER_interval_to_bgzip_0', '250': 'silac_analyzer', '251': 'fastq_to_tabular', '252': 'bedtools_sortbed', '253': 'CONVERTER_bed_gff_or_vcf_to_bigwig_0', '254': 'cshl_fastx_artifacts_filter', '255': 'predict_pipeline', '256': 'vt_normalize', '257': 'deeptools_profiler', '258': 'regex_replace', '259': 'get_subontology_from', '260': 'gatk2_haplotype_caller', '261': 'tp_cut_tool', '262': 'sam_bw_filter', '263': 'bedtools_coveragebed_counts', '264': 'cshl_fastx_quality_statistics', '265': 'EMBOSS: transeq101', '266': 'EMBOSS: newseq59', '267': 'bam2wig', '268': 'gatk2_realigner_target_creator', '269': 'p_clip_peaks', '270': 'meme_meme', '271': 'snpSift_annotate', '272': 'gops_coverage_1', '273': 'bedtools_genomecoveragebed', '274': 'smooth_running_window', '275': 'cshl_fastx_trimmer', '276': 'tp_replace_in_column', '277': 'sort1', '278': 'cufflinks', '279': 'FalseDiscoveryRate', '280': 'wolf_psort', '281': 'sam_to_bam', '282': 'DatamashOps', '283': 'bismark_bowtie', '284': 'samtools_flagstat', '285': 'macs2_bdgcmp', '286': 'cshl_multijoin', '287': 'Show beginning1', '288': 'picard_NormalizeFasta', '289': 'methtools_destrand', '290': 'trimmomatic', '291': 'samtools_stats', '292': 'bedtools_mergebed', '293': 'tp_split_on_column', '294': 'cat1', '295': 'htseq-count', '296': 'CONVERTER_bed_to_bgzip_0', '297': 'rseqc_bam2wig', '298': 'cummerbund_to_cuffdiff', '299': 'Remove beginning1', '300': 'IDPosteriorErrorProbability', '301': 'deseq2_single', '302': 'CONVERTER_gff_to_bed_0', '303': 'vcftools_isec', '304': 'openms_protein_quantifier', '305': 'picard_EstimateLibraryComplexity', '306': 'samtool_filter2', '307': 'tp_unfold_column_tool', '308': 'bowtie2', '309': 'XTandemAdapter'}\n"
     ]
    }
   ],
   "source": [
    "print(reverse_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recommendations(tool_sequence, labels, topk=20, max_seq_len=25):\n",
    "    tl_seq = tool_sequence.split(\",\")\n",
    "    last_tool_name = reverse_dictionary[str(tl_seq[-1])]\n",
    "    sample = np.zeros(max_seq_len)\n",
    "    for idx, tool_id in enumerate(tl_seq):\n",
    "        sample[idx] = int(tool_id)\n",
    "    sample_reshaped = np.reshape(sample, (1, max_seq_len))\n",
    "    tool_sequence_names = [reverse_dictionary[str(tool_pos)] for tool_pos in tool_sequence.split(\",\")]\n",
    "    # predict next tools for a test path\n",
    "    prediction = new_model.predict(sample_reshaped, verbose=0)\n",
    "    class_weighs = best_parameters[\"class_weights\"]\n",
    "    weight_val = list(class_weights.values())\n",
    "    weight_val = np.reshape(weight_val, (len(weight_val),))\n",
    "    prediction = np.reshape(prediction, (prediction.shape[1],))\n",
    "    #prediction = prediction * weight_val\n",
    "    prediction = prediction / float(np.max(prediction))\n",
    "    prediction_pos = np.argsort(prediction, axis=-1)\n",
    "    # get topk prediction\n",
    "    topk_prediction_pos = prediction_pos[-topk:]\n",
    "    topk_prediction_pos = [item for item in topk_prediction_pos if item != 0]\n",
    "    topk_prediction_val = [int(prediction[pos] * 100) for pos in topk_prediction_pos]\n",
    "    # read tool names using reverse dictionary\n",
    "    pred_tool_ids = [reverse_dictionary[str(tool_pos)] for tool_pos in topk_prediction_pos]\n",
    "    pred_tool_ids_sorted = dict()\n",
    "    for (tool_pos, tool_pred_val) in zip(topk_prediction_pos, topk_prediction_val):\n",
    "        tool_name = reverse_dictionary[str(tool_pos)]\n",
    "        pred_tool_ids_sorted[tool_name] = tool_pred_val\n",
    "    pred_tool_ids_sorted = dict(sorted(pred_tool_ids_sorted.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    ids_tools = dict()\n",
    "    keys = list(pred_tool_ids_sorted.keys())\n",
    "    tool_seq_name = \",\".join(tool_sequence_names)\n",
    "    print(\"Current tool sequence: \")\n",
    "    print()\n",
    "    print(tool_seq_name)\n",
    "    print()\n",
    "    print(\"Recommended tools for the tool sequence '%s' with their scores in decreasing order:\" % tool_seq_name)\n",
    "    print()\n",
    "    for i in pred_tool_ids_sorted:\n",
    "        print(i + \"(\" + str(pred_tool_ids_sorted[i]) + \"%)\")\n",
    "    for key in pred_tool_ids_sorted:\n",
    "        ids_tools[key] = dictionary[key]\n",
    "    print()\n",
    "    print(\"Tool ids:\")\n",
    "    print()\n",
    "    for i in ids_tools:\n",
    "        print(i + \"(\" + str(ids_tools[i]) + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indices of tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current tool sequence: \n",
      "\n",
      "coords2clnt.py\n",
      "\n",
      "Recommended tools for the tool sequence 'coords2clnt.py' with their scores in decreasing order:\n",
      "\n",
      "modencode_peakcalling_macs2(100%)\n",
      "scaffold2fasta(99%)\n",
      "deeptools_computeGCBias(99%)\n",
      "Show tail1(99%)\n",
      "deeptools_correctGCBias(99%)\n",
      "openms_id_mapper(99%)\n",
      "deeptools_computeMatrix(99%)\n",
      "deeptools_bamFingerprint(99%)\n",
      "tp_awk_tool(99%)\n",
      "flexbardsc(99%)\n",
      "gatk2_variant_apply_recalibration(98%)\n",
      "openms_id_file_converter(98%)\n",
      "computeMatrix(98%)\n",
      "bedtools_coveragebed_counts(98%)\n",
      "rmcontamination(98%)\n",
      "get_flanks1(98%)\n",
      "bgchem_fragment_merger(98%)\n",
      "bedtools_intersectBed(98%)\n",
      "cshl_cut_tool(98%)\n",
      "\n",
      "Tool ids:\n",
      "\n",
      "modencode_peakcalling_macs2(226)\n",
      "scaffold2fasta(227)\n",
      "deeptools_computeGCBias(183)\n",
      "Show tail1(30)\n",
      "deeptools_correctGCBias(11)\n",
      "openms_id_mapper(191)\n",
      "deeptools_computeMatrix(198)\n",
      "deeptools_bamFingerprint(42)\n",
      "tp_awk_tool(72)\n",
      "flexbardsc(181)\n",
      "gatk2_variant_apply_recalibration(142)\n",
      "openms_id_file_converter(77)\n",
      "computeMatrix(205)\n",
      "bedtools_coveragebed_counts(263)\n",
      "rmcontamination(166)\n",
      "get_flanks1(111)\n",
      "bgchem_fragment_merger(225)\n",
      "bedtools_intersectBed(214)\n",
      "cshl_cut_tool(91)\n"
     ]
    }
   ],
   "source": [
    "topk = 20 # set the maximum number of recommendations\n",
    "tool_seq = \"2\" # give tools ids in a sequence and see the recommendations. To know all the tool ids, \n",
    "                     # please print the variable 'reverse_dictionary'\n",
    "compute_recommendations(tool_seq, \"\", topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 25)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_20 (Embedding)     (None, 25, 49)            15190     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_8 (Spatial (None, 25, 49)            0         \n",
      "_________________________________________________________________\n",
      "gru_21 (GRU)                 (None, 25, 96)            42336     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 25, 96)            0         \n",
      "_________________________________________________________________\n",
      "gru_22 (GRU)                 [(None, 25, 96), (None, 9 55872     \n",
      "_________________________________________________________________\n",
      "bahdanau_attention_16 (Bahda ((None, 96), (None, 25, 1 18721     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 310)               30070     \n",
      "=================================================================\n",
      "Total params: 162,189\n",
      "Trainable params: 162,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(new_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 51.0, 'dropout': 0.22602806806492431, 'embedding_size': 33.0, 'learning_rate': 0.0032540638980664565, 'recurrent_dropout': 0.4216428563134349, 'spatial_dropout': 0.07267624883456103, 'units': 85.0, 'max_len': 25, 'dimensions': 310, 'class_weights': {'0': 0.0, '1': 1.2679033691330028, '2': 0.0953052070646881, '3': 2.36302973908641, '4': 0.3291822433584368, '5': 0.5994148283307562, '6': 0.0, '7': 4.893910221874146, '8': 0.38600688549788165, '9': 1.9296225475826647, '10': 5.249888185668796, '11': 1.2584609896100056, '12': 5.5060777871737265, '13': 0.2527023535557542, '14': 0.09531017980432493, '15': 0.09531017980432493, '16': 0.38668123051024755, '17': 4.116595171156921, '18': 7.360040357734192, '19': 3.6149637711637683, '20': 0.09531017980432493, '21': 0.1879510232386989, '22': 5.78484241624876, '23': 0.0, '24': 0.09543005443725577, '25': 7.13966033596492, '26': 0.09473615144520271, '27': 2.7111174575911785, '28': 0.0, '29': 2.1856234256723175, '30': 0.02803959057123678, '31': 0.0, '32': 0.38750290259636944, '33': 0.6712322429062169, '34': 5.631504993955934, '35': 0.9666204988181899, '36': 0.0, '37': 0.41178132541076307, '38': 5.834387317169895, '39': 4.382679657408116, '40': 1.6582978932139152, '41': 0.0, '42': 0.0, '43': 6.258042318888258, '44': 5.6680003185450945, '45': 4.502839461540633, '46': 6.73240933592858, '47': 3.7509861930519683, '48': 0.5534520941998734, '49': 5.8328269641651795, '50': 0.0, '51': 0.0, '52': 5.785395391705502, '53': 5.479313217732502, '54': 4.220534985284344, '55': 0.0, '56': 0.0, '57': 0.07250647687303469, '58': 0.06399421365412633, '59': 0.0, '60': 0.0, '61': 0.06263988862502112, '62': 3.856428173309885, '63': 2.0268152750688944, '64': 3.2457648765922755, '65': 4.710430790975013, '66': 7.160087138220143, '67': 4.604344316451709, '68': 2.4336133554004498, '69': 0.0, '70': 1.31610213587424, '71': 0.07964582277129585, '72': 0.0, '73': 0.0, '74': 0.384289751049462, '75': 1.4393338223204117, '76': 0.0, '77': 0.5097738248193585, '78': 0.09530912525831431, '79': 3.6682516181767437, '80': 0.0, '81': 2.285273209338971, '82': 4.586322377523295, '83': 0.0, '84': 4.123490009141191, '85': 0.3241120995875124, '86': 1.1169614287908518, '87': 6.97617687621502, '88': 3.3953636085831604, '89': 5.374815302782456, '90': 0.07041739104367695, '91': 0.09531017980432493, '92': 0.0, '93': 3.747675549429567, '94': 0.44291052841248557, '95': 7.0405799283399615, '96': 0.026003879333510976, '97': 8.668715028378008, '98': 1.8836586138183606, '99': 3.2681268641517134, '100': 0.0, '101': 6.446513155404975, '102': 4.6549122778829055, '103': 3.587600554538827, '104': 0.39796300423345954, '105': 0.09538827675467865, '106': 1.2530738801573276, '107': 0.0, '108': 3.490589678926948, '109': 4.387828804608451, '110': 0.07041739104367695, '111': 0.6018501587539669, '112': 5.102553377787591, '113': 0.0, '114': 0.09531017980432493, '115': 5.345744330744355, '116': 0.6878727954132038, '117': 0.6878727954132038, '118': 0.41207446477734766, '119': 0.0, '120': 5.883043798153562, '121': 5.6889911384039635, '122': 4.298725613384298, '123': 0.07250647687303469, '124': 4.146814615224232, '125': 4.878760174427442, '126': 2.651965442452904, '127': 3.0007198150650303, '128': 5.631658856850509, '129': 0.0, '130': 3.0032081216359656, '131': 4.26323736893777, '132': 3.7214488425624106, '133': 2.234375470401864, '134': 6.538477441630863, '135': 5.793976976269424, '136': 0.6600210747001517, '137': 1.5795052961728004, '138': 2.07093447397118, '139': 1.479424008472176, '140': 0.0, '141': 1.5818836937517387, '142': 2.1662269660607643, '143': 0.5889135741457597, '144': 0.09531017980432493, '145': 4.271610051538416, '146': 4.38806310770465, '147': 3.0794785217240763, '148': 5.104125637183595, '149': 3.988520976400871, '150': 0.13845555899307133, '151': 5.913932166319434, '152': 2.220410534624088, '153': 0.16243582304452936, '154': 4.993573370845278, '155': 4.206458375495826, '156': 0.09531073434962559, '157': 0.07964582277129585, '158': 0.6875761360691492, '159': 3.59562485251039, '160': 6.562585326657728, '161': 0.0, '162': 2.802362331505732, '163': 0.5368147223842971, '164': 1.8989670255555637, '165': 6.134101924823247, '166': 0.09359915319644818, '167': 0.07250647687303469, '168': 6.130624010985935, '169': 4.925770268699728, '170': 6.77337540620297, '171': 0.07189469179761168, '172': 0.6418784174504478, '173': 4.8283283891949615, '174': 2.9626925471243615, '175': 0.09531017980432493, '176': 1.3535022515442852, '177': 0.0, '178': 0.0, '179': 5.588244857534695, '180': 0.09187671949238563, '181': 0.22314355131420976, '182': 3.487433480173297, '183': 0.3668217386599276, '184': 7.422373700986824, '185': 0.09530577070369572, '186': 0.0, '187': 3.8678880399081907, '188': 0.061612021235966506, '189': 2.3826786024540727, '190': 0.0, '191': 0.0, '192': 5.382251053396031, '193': 0.0, '194': 4.566142639960839, '195': 3.709639438928503, '196': 0.016930742674575377, '197': 0.0, '198': 0.0, '199': 5.26830770223046, '200': 0.0, '201': 6.370256557121318, '202': 4.812256047599217, '203': 4.370482989692134, '204': 0.0, '205': 0.0, '206': 3.5483850691681953, '207': 2.1056058939006714, '208': 0.34380222790464565, '209': 4.490221318991273, '210': 5.992613886364503, '211': 3.698178191785774, '212': 4.071363882392451, '213': 0.9141247037279912, '214': 6.982862751468942, '215': 0.0, '216': 0.09531017980432493, '217': 5.225949787277793, '218': 0.5089603291852106, '219': 0.6600210747001517, '220': 0.0, '221': 0.0, '222': 0.6695903903040974, '223': 2.451005098112319, '224': 0.39373655675765357, '225': 3.9202774825001394, '226': 5.767059074749979, '227': 1.4713061761506316, '228': 0.07189469179761168, '229': 0.09532353426060833, '230': 5.799092654460526, '231': 2.282374674422305, '232': 0.0, '233': 5.586561781205797, '234': 0.1153108445307964, '235': 0.0, '236': 1.2623529373962634, '237': 0.0, '238': 0.09530406160379044, '239': 6.190901061884645, '240': 4.381192953883603, '241': 2.4045927770886624, '242': 1.5625746771441749, '243': 0.0, '244': 6.576772652723754, '245': 0.44941864223599143, '246': 5.330374911417734, '247': 0.09048175077058784, '248': 5.118858189393999, '249': 0.07250647687303469, '250': 2.0360119837525, '251': 0.0, '252': 0.0, '253': 0.07250647687303469, '254': 0.6280071025232983, '255': 0.0, '256': 5.888814776503156, '257': 4.317180373922666, '258': 1.650222229444567, '259': 0.1823215567939546, '260': 4.167255167580128, '261': 0.09543005443725577, '262': 1.7787480381679142, '263': 0.45622654074899477, '264': 0.0, '265': 2.163323025660538, '266': 0.08976817851796072, '267': 4.440851943402857, '268': 2.9900494905861095, '269': 5.185388581262361, '270': 6.509065023535706, '271': 3.589797968190993, '272': 4.695671971973471, '273': 1.683676062828553, '274': 0.0869905767733068, '275': 0.10258264394232028, '276': 1.9168309432747128, '277': 6.278333789302737, '278': 0.0, '279': 1.4079816206942064, '280': 0.0, '281': 0.5196069448607583, '282': 1.5018192446243235, '283': 5.755483261770645, '284': 0.0, '285': 0.026118307998642735, '286': 4.556972389179466, '287': 4.568367283876591, '288': 4.500920164614292, '289': 6.297845696992248, '290': 0.4054651081081644, '291': 0.0, '292': 0.1359871659931982, '293': 0.6960840387669792, '294': 0.0, '295': 1.018324172551051, '296': 5.2482257831848935, '297': 0.0, '298': 1.606719464801262, '299': 0.6600210747001517, '300': 0.06805043152989372, '301': 4.432006566978902, '302': 5.65510384781625, '303': 0.0, '304': 0.0, '305': 0.8715893263269244, '306': 2.8087371203020917, '307': 0.0, '308': 3.0892559462316123, '309': 6.077795136866647}}\n"
     ]
    }
   ],
   "source": [
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
