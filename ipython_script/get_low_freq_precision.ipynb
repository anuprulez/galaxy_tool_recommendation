{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/kumara/miniconda3/envs/tool_prediction_gru_wc/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kumara/miniconda3/envs/tool_prediction_gru_wc/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kumara/miniconda3/envs/tool_prediction_gru_wc/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kumara/miniconda3/envs/tool_prediction_gru_wc/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kumara/miniconda3/envs/tool_prediction_gru_wc/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kumara/miniconda3/envs/tool_prediction_gru_wc/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import operator\n",
    "\n",
    "import h5py\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as data_file:\n",
    "        data = json.loads(data_file.read())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_path):\n",
    "    reverse_dictionary = dict((str(v), k) for k, v in dictionary.items())\n",
    "    model_weights = list()\n",
    "    weight_ctr = 0\n",
    "    for index, item in enumerate(trained_model.keys()):\n",
    "        if \"weight_\" in item:\n",
    "            d_key = \"weight_\" + str(weight_ctr)\n",
    "            weights = trained_model.get(d_key).value\n",
    "            model_weights.append(weights)\n",
    "            weight_ctr += 1\n",
    "    # set the model weights\n",
    "    loaded_model.set_weights(model_weights)\n",
    "    return loaded_model, dictionary, reverse_dictionary\n",
    "\n",
    "\n",
    "def get_predicted_tools(base_tools, predictions, topk):\n",
    "    \"\"\"\n",
    "    Get predicted tools. If predicted tools are less in number, combine them with published tools\n",
    "    \"\"\"\n",
    "    precision = np.nan\n",
    "    intersection = list()\n",
    "    if len(base_tools) > 0:\n",
    "        intersection = list(set(predictions).intersection(set(base_tools)))\n",
    "        precision = len(intersection) / float(len(predictions))\n",
    "    return intersection[:topk], precision\n",
    "\n",
    "\n",
    "def sort_by_usage(t_list, class_weights, d_dict):\n",
    "    \"\"\"\n",
    "    Sort predictions by usage/class weights\n",
    "    \"\"\"\n",
    "    tool_dict = dict()\n",
    "    for tool in t_list:\n",
    "        t_id = d_dict[tool]\n",
    "        tool_dict[tool] = class_weights[str(t_id)]\n",
    "    #tool_dict = dict(sorted(tool_dict.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    return list(tool_dict.keys()), list(tool_dict.values())\n",
    "\n",
    "\n",
    "def separate_predictions(base_tools, predictions, last_tool_name, weight_values, topk):\n",
    "    \"\"\"\n",
    "    Get predictions from published and normal workflows\n",
    "    \"\"\"\n",
    "    last_base_tools = list()\n",
    "    predictions = predictions * weight_values\n",
    "    prediction_pos = np.argsort(predictions, axis=-1)\n",
    "    topk_prediction_pos = prediction_pos[-topk:]\n",
    "    # get tool ids\n",
    "    pred_tool_ids = [reverse_dictionary[str(tool_pos)] for tool_pos in topk_prediction_pos]\n",
    "    if last_tool_name in base_tools:\n",
    "        last_base_tools = base_tools[last_tool_name]\n",
    "        if type(last_base_tools).__name__ == \"str\":\n",
    "            # get published or compatible tools for the last tool in a sequence of tools\n",
    "            last_base_tools = last_base_tools.split(\",\")\n",
    "    # get predicted tools\n",
    "    p_tools, precision = get_predicted_tools(last_base_tools, pred_tool_ids, topk)\n",
    "    sorted_c_t, sorted_c_v = sort_by_usage(p_tools, class_weights, dictionary)\n",
    "    return sorted_c_t, sorted_c_v, precision\n",
    "\n",
    "\n",
    "def compute_recommendations(model, tool_sequence, labels, dictionary, reverse_dictionary, class_weights, topk=10, max_seq_len=25):\n",
    "    tl_seq = tool_sequence.split(\",\")\n",
    "    tl_seq_ids = [str(dictionary[t]) for t in tl_seq]\n",
    "    last_tool_name = tl_seq[-1]\n",
    "    sample = np.zeros(max_seq_len)\n",
    "    weight_val = list(class_weights.values())\n",
    "    weight_val = np.reshape(weight_val, (len(weight_val),))\n",
    "    for idx, tool_id in enumerate(tl_seq_ids):\n",
    "        sample[idx] = int(tool_id)\n",
    "    sample_reshaped = np.reshape(sample, (1, max_seq_len))\n",
    "    tool_sequence_names = [reverse_dictionary[str(tool_pos)] for tool_pos in tl_seq_ids]\n",
    "    # predict next tools for a test path\n",
    "    prediction = model.predict(sample_reshaped, verbose=0)\n",
    "    nw_dimension = prediction.shape[1]\n",
    "    prediction = np.reshape(prediction, (nw_dimension,))\n",
    "    \n",
    "    half_len = int(nw_dimension / 2)\n",
    "    \n",
    "    pub_t, pub_v, pub_prec = separate_predictions(standard_connections, prediction[:half_len], last_tool_name, weight_val, topk)\n",
    "    # get recommended tools from normal workflows\n",
    "    c_t, c_v, c_prec = separate_predictions(compatible_tools, prediction[half_len:], last_tool_name, weight_val, topk)\n",
    "    \n",
    "    return pub_prec, c_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kumara/miniconda3/envs/tool_prediction_gru_wc/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "base_path = \"../output_files/data_20_05/gru_wc/run1/\"\n",
    "original_freq = read_file(base_path + \"freq_dict_names.txt\")\n",
    "balanced_freq = read_file(base_path + \"generated_tool_frequencies.txt\")\n",
    "test_paths = read_file(base_path + \"test_paths_dict.txt\")\n",
    "\n",
    "model_path = base_path + \"tool_recommendation_model_20_05.hdf5\"\n",
    "trained_model = h5py.File(model_path, 'r')\n",
    "model_config = json.loads(trained_model.get('model_config').value)\n",
    "dictionary = json.loads(trained_model.get('data_dictionary').value)\n",
    "class_weights = json.loads(trained_model.get('class_weights').value)\n",
    "standard_connections = json.loads(trained_model.get('standard_connections').value)\n",
    "compatible_tools = json.loads(trained_model.get('compatible_tools').value)\n",
    "loaded_model = model_from_json(model_config)\n",
    "model, dictionary, reverse_dictionary = create_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tool sequences: 45955\n",
      "Last tool frequency: 1\n",
      "Published precision: 1.0\n",
      "Normal precision: 0.8305084745762712\n",
      "Mean frequency of last tools: 1.0\n",
      "Number of paths used : 59\n",
      "===========================================================\n",
      "Last tool frequency: 3\n",
      "Published precision: 0.9375\n",
      "Normal precision: 0.8636363636363636\n",
      "Mean frequency of last tools: 2.028409090909091\n",
      "Number of paths used : 176\n",
      "===========================================================\n",
      "Last tool frequency: 5\n",
      "Published precision: 0.9642857142857143\n",
      "Normal precision: 0.8644688644688645\n",
      "Mean frequency of last tools: 2.901098901098901\n",
      "Number of paths used : 273\n",
      "===========================================================\n",
      "Last tool frequency: 7\n",
      "Published precision: 0.9538461538461539\n",
      "Normal precision: 0.8579545454545454\n",
      "Mean frequency of last tools: 3.710227272727273\n",
      "Number of paths used : 352\n",
      "===========================================================\n",
      "Last tool frequency: 9\n",
      "Published precision: 0.967032967032967\n",
      "Normal precision: 0.8905908096280087\n",
      "Mean frequency of last tools: 4.818380743982495\n",
      "Number of paths used : 457\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tool sequences: %d\" % len(test_paths))\n",
    "num_calibrations = 10\n",
    "step = 1\n",
    "topk = 1\n",
    "calibrations_p_prec = list()\n",
    "calibrations_c_prec = list()\n",
    "calibrations_freq = list()\n",
    "calibrations_n_paths = list()\n",
    "for i in range(1, num_calibrations, 1):\n",
    "    complete_p_prec = list()\n",
    "    complete_c_prec = list()\n",
    "    freq = list()\n",
    "    ctr = 0\n",
    "    for t_seq in test_paths:\n",
    "        last_tool = t_seq.split(\",\")[-1]\n",
    "        last_tool_name = reverse_dictionary[last_tool]\n",
    "        t_seq_n = [reverse_dictionary[tid] for tid in t_seq.split(\",\")]\n",
    "        t_seq_n = \",\".join(t_seq_n)\n",
    "        if last_tool_name in original_freq:\n",
    "            if original_freq[last_tool_name] <= i:\n",
    "                p_prec, c_prec = compute_recommendations(model, t_seq_n, \"\", dictionary, reverse_dictionary, class_weights, topk)\n",
    "                complete_p_prec.append(p_prec)\n",
    "                complete_c_prec.append(c_prec)\n",
    "                freq.append(original_freq[last_tool_name])\n",
    "                ctr+= 1\n",
    "    mean_p_prec = np.nanmean(complete_p_prec)\n",
    "    mean_c_prec = np.nanmean(complete_c_prec)\n",
    "    mean_freq = np.mean(freq)\n",
    "    calibrations_p_prec.append(str(mean_p_prec))\n",
    "    calibrations_c_prec.append(str(mean_c_prec))\n",
    "    calibrations_freq.append(str(mean_freq))\n",
    "    calibrations_n_paths.append(str(ctr))\n",
    "    print(\"Last tool frequency: %s\" % str(i))\n",
    "    print(\"Published precision: %s\" % str(mean_p_prec))\n",
    "    print(\"Normal precision: %s\" % str(mean_c_prec))\n",
    "    print(\"Mean frequency of last tools: %s\" % str(mean_freq))\n",
    "    print(\"Number of paths used : %s\" % ctr)\n",
    "    print(\"===========================================================\")\n",
    "    \n",
    "with open(base_path + \"test_paths_low_freq_tool_perf.txt\", \"w\") as f:\n",
    "    results = \"\"\n",
    "    results = \",\".join(calibrations_p_prec)\n",
    "    results += \"\\t\"+ \",\".join(calibrations_c_prec)\n",
    "    results += \"\\t\"+ \",\".join(calibrations_freq)\n",
    "    results += \"\\t\"+ \",\".join(calibrations_n_paths)\n",
    "    f.write(results)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
