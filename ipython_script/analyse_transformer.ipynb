{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8439389d-c89d-4d0a-90ae-fbe6706cd498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 16:25:23.794105: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-09 16:25:23.794137: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0256fa07-f9b1-4e18-bed2-a0ab93ef20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = (20, 20)\n",
    "font = {'family': 'serif', 'size': 20}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "batch_size = 10\n",
    "test_batches = 1\n",
    "n_topk = 2\n",
    "max_seq_len = 25\n",
    "\n",
    "base_path = \"../log_08_08_22_2/\"\n",
    "predict_rnn = False\n",
    "\n",
    "#base_path = \"log_08_08_22_rnn/\"\n",
    "#predict_rnn = True # set to True for RNN model\n",
    "\n",
    "# log_08_08_22_2 (finish time: 40,000 steps in 158683.60082054138 seconds)\n",
    "# log_08_08_22_rnn (finish time: 40,000 steps in 173480.83078551292 seconds)\n",
    "\n",
    "#\"log_03_08_22_1/\" Balanced data with really selection of low freq tools - random choice\n",
    "# RNN: log_01_08_22_3_rnn\n",
    "# Transformer: log_01_08_22_0\n",
    "\n",
    "model_number = 40000\n",
    "model_path = base_path + \"saved_model/\" + str(model_number) + \"/tf_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd224834-b321-4f82-880b-83ea6acca632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 16:25:33.408151: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-09 16:25:33.408717: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-09 16:25:33.409727: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (anupkumar-HP-ProBook-450-G5): /proc/driver/nvidia/version does not exist\n",
      "2022-08-09 16:25:33.429100: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def remove_file(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Read a file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        file_content = json.loads(json_file.read())\n",
    "    return file_content\n",
    "\n",
    "\n",
    "def write_file(file_path, content):\n",
    "    \"\"\"\n",
    "    Write a file\n",
    "    \"\"\"\n",
    "    remove_file(file_path)\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json_file.write(json.dumps(content))\n",
    "\n",
    "\n",
    "r_dict = read_file(base_path + \"data/rev_dict.txt\")\n",
    "f_dict = read_file(base_path + \"data/f_dict.txt\")\n",
    "\n",
    "path_test_data = base_path + \"saved_data/test.h5\"\n",
    "\n",
    "file_obj = h5py.File(path_test_data, 'r')\n",
    "\n",
    "test_input = np.array(file_obj[\"input\"])\n",
    "test_target = np.array(file_obj[\"target\"])\n",
    "\n",
    "class_weights = read_file(base_path + \"data/class_weights.txt\")\n",
    "compatible_tools = read_file(base_path + \"data/compatible_tools.txt\")\n",
    "\n",
    "#tool_freq = utils.read_file(base_path + \"data/freq_dict_names.txt\")\n",
    "published_connections = read_file(base_path + \"data/published_connections.txt\")\n",
    "\n",
    "c_weights = list(class_weights.values())\n",
    "\n",
    "c_weights = tf.convert_to_tensor(c_weights, dtype=tf.float32)\n",
    "\n",
    "te_lowest_t_ids = read_file(base_path + \"data/te_lowest_t_ids.txt\")\n",
    "lowest_t_ids = [int(item) for item in te_lowest_t_ids.split(\",\")]\n",
    "tool_tr_freq = read_file(base_path + \"data/all_sel_tool_ids.txt\")\n",
    "\n",
    "all_sel_tool_ids = read_file(base_path + \"data/all_sel_tool_ids.txt\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0524ee9c-2b57-432b-a05c-5533271ebf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ae2b83-55f4-4075-8c63-babcf9b86d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generated_attention(attention_weights, i_names, f_dict, r_dict):\n",
    "\n",
    "    #print(attention_weights.shape)\n",
    "    attention_heads = tf.squeeze(attention_weights, 0)\n",
    "    n_heads = attention_heads.shape[1]\n",
    "    i_names = i_names.split(\",\")\n",
    "    in_tokens = i_names\n",
    "    out_tokens = i_names\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "\n",
    "    for h, head in enumerate(attention_heads):\n",
    "      ax = fig.add_subplot(2, 4, h+1)\n",
    "      plot_attention_head(in_tokens, out_tokens, head)\n",
    "      ax.set_xlabel(f'Head {h+1}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_attention_head(in_tokens, out_tokens, attention):\n",
    "  # The plot is of the attention when a token was generated.\n",
    "  # The model didn't generate `<START>` in the output. Skip it.\n",
    "  #translated_tokens = translated_tokens[1:]\n",
    "  #print(attention)\n",
    "  ax = plt.gca()\n",
    "  ax.matshow(attention[:len(in_tokens), :len(out_tokens)])\n",
    "  #ax.matshow(attention)\n",
    "\n",
    "  ax.set_xticks(range(len(in_tokens)))\n",
    "  ax.set_yticks(range(len(out_tokens)))\n",
    "\n",
    "  ax.set_xticklabels(in_tokens, rotation=90)\n",
    "  ax.set_yticklabels(out_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9390e063-d2c1-4a5b-83f2-1ec4235a81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss_acc():\n",
    "    epo_tr_batch_loss = read_file(base_path + \"data/epo_tr_batch_loss.txt\").split(\",\")\n",
    "\n",
    "    #print(len(epo_tr_batch_loss))\n",
    "    epo_tr_batch_loss = [np.round(float(item), 4) for item in epo_tr_batch_loss]\n",
    "\n",
    "    epo_tr_batch_acc = read_file(base_path + \"data/epo_tr_batch_acc.txt\").split(\",\")\n",
    "    epo_tr_batch_acc = [np.round(float(item), 4) for item in epo_tr_batch_acc]\n",
    "\n",
    "    epo_te_batch_loss = read_file(base_path + \"data/epo_te_batch_loss.txt\").split(\",\")\n",
    "    epo_te_batch_loss = [np.round(float(item), 4) for item in epo_te_batch_loss]\n",
    "\n",
    "    epo_te_batch_acc = read_file(base_path + \"data/epo_te_precision.txt\").split(\",\")\n",
    "    epo_te_batch_acc = [np.round(float(item), 4) for item in epo_te_batch_acc]\n",
    "\n",
    "    plot_loss_acc(epo_tr_batch_loss, epo_tr_batch_acc, \"training\")\n",
    "    plot_loss_acc(epo_te_batch_loss, epo_te_batch_acc, \"test\")\n",
    "\n",
    "    epo_te_low_batch_acc = read_file(base_path + \"data/epo_low_te_precision.txt\").split(\",\")\n",
    "    epo_te_low_batch_acc = [np.round(float(item), 4) for item in epo_te_low_batch_acc]\n",
    "\n",
    "    plot_low_te_prec(epo_te_low_batch_acc, \"Low test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa590092-8a14-485f-ab29-612852d95e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    return tf.saved_model.load(model_path)\n",
    "tf_loaded_model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e90a9344-73c6-4577-a751-aed336aa5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_balanced_tr_y(x_seqs, y_labels, ulabels_tr_y_dict):\n",
    "    batch_y_tools = list(ulabels_tr_y_dict.keys())\n",
    "    random.shuffle(batch_y_tools)\n",
    "    label_tools = list()\n",
    "    rand_batch_indices = list()\n",
    "\n",
    "    for l_tool in batch_y_tools:\n",
    "        seq_indices = ulabels_tr_y_dict[l_tool]\n",
    "        random.shuffle(seq_indices)\n",
    "        \n",
    "        if seq_indices[0] not in rand_batch_indices:\n",
    "            rand_batch_indices.append(seq_indices[0])\n",
    "            label_tools.append(l_tool)\n",
    "        if len(rand_batch_indices) == batch_size:\n",
    "            break\n",
    "    \n",
    "    x_batch_train = x_seqs[rand_batch_indices]\n",
    "    y_batch_train = y_labels[rand_batch_indices]\n",
    "\n",
    "    unrolled_x = tf.convert_to_tensor(x_batch_train, dtype=tf.int64)\n",
    "    unrolled_y = tf.convert_to_tensor(y_batch_train, dtype=tf.int64)\n",
    "    return unrolled_x, unrolled_y, label_tools, rand_batch_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad68747f-5586-46d3-bb27-ce601e6907b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "991ec9f5-77a9-4278-903e-2ee8ac1d5ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_low_freq_seq():\n",
    "    \n",
    "    \n",
    "    low_te_data = test_input[lowest_t_ids]\n",
    "    low_te_labels = test_target[lowest_t_ids]\n",
    "    #print(\"Test lowest ids\", low_te_data.shape, low_te_labels.shape)\n",
    "    #low_te_pred_batch, low_att_weights = tf_loaded_model([low_te_data], training=False)\n",
    "    low_topk = 5\n",
    "    low_te_precision = list()\n",
    "    for i, (low_inp, low_tar) in enumerate(zip(low_te_data, low_te_labels)):\n",
    "        if predict_rnn is True:\n",
    "            low_prediction = tf_loaded_model([low_inp], training=False)\n",
    "        else:\n",
    "            low_prediction, att_weights = tf_loaded_model([low_inp], training=False)\n",
    "        #print(low_prediction.shape)\n",
    "        \n",
    "        low_label_pos = np.where(low_tar > 0)[0]\n",
    "        low_topk = len(low_label_pos)\n",
    "        low_topk_pred = tf.math.top_k(low_prediction, k=low_topk, sorted=True)\n",
    "        low_topk_pred = low_topk_pred.indices.numpy()[0]\n",
    "        \n",
    "        low_label_pos_tools = [r_dict[str(item)] for item in low_label_pos if item not in [0, \"0\"]]\n",
    "        low_pred_label_pos_tools = [r_dict[str(item)] for item in low_topk_pred if item not in [0, \"0\"]]\n",
    "\n",
    "        low_intersection = list(set(low_label_pos_tools).intersection(set(low_pred_label_pos_tools)))\n",
    "        low_pred_precision = float(len(low_intersection)) / len(low_label_pos)\n",
    "        low_te_precision.append(low_pred_precision)\n",
    "        \n",
    "        #low_inp = low_inp.numpy()\n",
    "        low_inp_pos = np.where(low_inp > 0)[0]\n",
    "\n",
    "        print(\"Low: test tool sequence: {}\".format([r_dict[str(int(item))] for item in low_inp[low_inp_pos]]))\n",
    "        print()\n",
    "        print(\"Low: True labels: {}\".format(low_label_pos_tools))\n",
    "        print()\n",
    "        print(\"Low: Predicted labels: {}, Precision: {}\".format(low_pred_label_pos_tools, low_pred_precision))\n",
    "        print(\"-----------------\")\n",
    "        print()\n",
    "    \n",
    "    if len(lowest_t_ids) > 0:\n",
    "        print(\"Low test prediction precision: {}\".format(np.mean(low_te_precision)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23c48f7-8ff3-4342-85c2-efe1e3ffe42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_tool_in_tr(r_dict):\n",
    "    \n",
    "\n",
    "    freq_dict = dict()\n",
    "    freq_dict_names = dict()\n",
    "\n",
    "    for tool_id in all_sel_tool_ids:\n",
    "        if tool_id not in freq_dict:\n",
    "            freq_dict[tool_id] = 0\n",
    "\n",
    "        if tool_id not in freq_dict_names:\n",
    "            freq_dict_names[r_dict[str(int(tool_id))]] = 0\n",
    "\n",
    "        freq_dict[tool_id] += 1\n",
    "        freq_dict_names[r_dict[str(int(tool_id))]] += 1\n",
    "\n",
    "    s_freq = dict(sorted(freq_dict.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    s_freq_names = dict(sorted(freq_dict_names.items(), key=lambda kv: kv[1], reverse=True))\n",
    "\n",
    "\n",
    "    write_file(base_path + \"data/s_freq_names.txt\", s_freq_names)\n",
    "    write_file(base_path + \"data/s_freq.txt\", s_freq)\n",
    "\n",
    "    return s_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e7626fc-8703-4aac-afa0-c72a41aa6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_u_tr_labels(y_tr):\n",
    "    labels = list()\n",
    "    labels_pos_dict = dict()\n",
    "    for i, item in enumerate(y_tr):\n",
    "        label_pos = np.where(item > 0)[0]\n",
    "        labels.extend(label_pos)\n",
    "        for label in label_pos:\n",
    "            if label not in labels_pos_dict:\n",
    "                labels_pos_dict[label] = list()\n",
    "            labels_pos_dict[label].append(i)\n",
    "\n",
    "    u_labels = list(set(labels))\n",
    "    \n",
    "    for item in labels_pos_dict:\n",
    "        labels_pos_dict[item] = list(set(labels_pos_dict[item]))\n",
    "    return u_labels, labels_pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06683e24-e729-458e-b9fb-a1d4cd1f650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq():\n",
    "\n",
    "    #visualize_loss_acc()\n",
    "\n",
    "    \n",
    "    #sys.exit()\n",
    "\n",
    "    #verify_training_sampling(tool_tr_freq, r_dict)\n",
    "    \n",
    "    #r_dict = read_file(base_path + \"data/rev_dict.txt\")\n",
    "    #f_dict = read_file(base_path + \"data/f_dict.txt\")\n",
    "    \n",
    "    all_tr_label_tools = verify_tool_in_tr(r_dict)\n",
    "\n",
    "    all_tr_label_tools_ids = list(all_tr_label_tools.keys())\n",
    "    all_tr_label_tools_ids = [int(t) for t in all_tr_label_tools_ids]\n",
    "    \n",
    "    \n",
    "    print(test_input.shape, test_target.shape)\n",
    "\n",
    "    \n",
    "    u_te_y_labels, u_te_y_labels_dict = get_u_tr_labels(test_target)\n",
    "\n",
    "    precision = list()\n",
    "    pub_prec_list = list()\n",
    "    error_label_tools = list()\n",
    "\n",
    "    for j in range(test_batches):\n",
    "        #te_x_batch, y_train_batch = sample_balanced(test_input, test_target, ulabels_te_dict)\n",
    "        te_x_batch, y_train_batch, selected_label_tools, bat_ind = sample_balanced_tr_y(test_input, test_target, u_te_y_labels_dict)\n",
    "        #print(j * batch_size, j * batch_size + batch_size)\n",
    "        #te_x_batch = test_input[j * batch_size : j * batch_size + batch_size, :]\n",
    "        #y_train_batch = test_target[j * batch_size : j * batch_size + batch_size, :]\n",
    "\n",
    "        for i, (inp, tar) in enumerate(zip(te_x_batch, y_train_batch)):\n",
    "\n",
    "            t_ip = inp\n",
    "            if len(np.where(inp > 0)[0]) < max_seq_len:\n",
    "                real_prediction = np.where(tar > 0)[0]\n",
    "                target_pos = list(set(all_tr_label_tools_ids).intersection(set(real_prediction)))\n",
    "                #print(\"Real predicted tools: {}, Actual trained labels: {}\".format(real_prediction, target_pos))\n",
    "                #print()\n",
    "                t_ip = tf.convert_to_tensor(t_ip, dtype=tf.int64)\n",
    "                if predict_rnn is True:\n",
    "                    prediction = tf_loaded_model([t_ip], training=False)\n",
    "                else:\n",
    "                    prediction, att_weights = tf_loaded_model([t_ip], training=False)\n",
    "                prediction_wts = tf.math.multiply(c_weights, prediction)\n",
    "\n",
    "                n_topk = len(target_pos)\n",
    "                top_k = tf.math.top_k(prediction, k=n_topk, sorted=True)\n",
    "                top_k_wts = tf.math.top_k(prediction_wts, k=n_topk, sorted=True)\n",
    "\n",
    "                t_ip = t_ip.numpy()\n",
    "                label_pos = np.where(t_ip > 0)[0]\n",
    "\n",
    "                i_names = \",\".join([r_dict[str(item)] for item in t_ip[label_pos]  if item not in [0, \"0\"]])\n",
    "                t_names = \",\".join([r_dict[str(int(item))] for item in target_pos  if item not in [0, \"0\"]])\n",
    "\n",
    "                last_i_tool = [r_dict[str(item)] for item in t_ip[label_pos]][-1]\n",
    "\n",
    "                true_tools = [r_dict[str(int(item))] for item in target_pos]\n",
    "\n",
    "                #print(\"Selected tool in true tools: {}\".format(s_label_tool in true_tools))\n",
    "\n",
    "                pred_tools = [r_dict[str(item)] for item in top_k.indices.numpy()[0]  if item not in [0, \"0\"]]\n",
    "                pred_tools_wts = [r_dict[str(item)] for item in top_k_wts.indices.numpy()[0]  if item not in [0, \"0\"]]\n",
    "\n",
    "                intersection = list(set(true_tools).intersection(set(pred_tools)))\n",
    "\n",
    "                pub_prec = 0.0\n",
    "                pub_prec_wt = 0.0\n",
    "\n",
    "                if last_i_tool in published_connections:\n",
    "                    true_pub_conn = published_connections[last_i_tool]\n",
    "                    #print(\"Test batch {}, True published tools: {}\".format(j+1, true_pub_conn)) \n",
    "                    #print()\n",
    "                    if len(pred_tools) > 0:\n",
    "                        intersection_pub = list(set(true_pub_conn).intersection(set(pred_tools)))\n",
    "                        intersection_pub_wt = list(set(true_pub_conn).intersection(set(pred_tools_wts)))\n",
    "                        pub_prec = float(len(intersection_pub)) / len(pred_tools)\n",
    "                        pub_prec_list.append(pub_prec)\n",
    "                        pub_prec_wt = float(len(intersection_pub_wt)) / len(pred_tools)\n",
    "                    else:\n",
    "                        pub_prec = False\n",
    "                        pub_prec_wt = False\n",
    "\n",
    "                if len(pred_tools) > 0:\n",
    "                    pred_precision = float(len(intersection)) / len(pred_tools)\n",
    "                    precision.append(pred_precision)\n",
    "\n",
    "                if pred_precision < 2.0:\n",
    "            \n",
    "                    print(\"Test batch {}, Tool sequence: {}\".format(j+1, [r_dict[str(item)] for item in t_ip[label_pos]]))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, True tools: {}\".format(j+1, true_tools))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, Predicted top {} tools: {}\".format(j+1, n_topk, pred_tools))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, Predicted top {} tools with weights: {}\".format(j+1, n_topk, pred_tools_wts))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, Precision: {}\".format(j+1, pred_precision)) \n",
    "                    print()\n",
    "                    print(\"Test batch {}, Published precision: {}\".format(j+1, pub_prec))\n",
    "                    print()\n",
    "                    print(\"Test batch {}, Published precision with weights: {}\".format(j+1, pub_prec_wt))\n",
    "                    #error_label_tools.append(select_tools[i])\n",
    "                    print(\"=========================\")\n",
    "                print(\"--------------------------\")\n",
    "                generated_attention(att_weights, i_names, f_dict, r_dict)\n",
    "        \n",
    "                print(\"Batch {} prediction finished ...\".format(j+1))\n",
    "\n",
    "    if test_batches > 0:\n",
    "        print(\"Precision@{}: {}\".format(n_topk, np.mean(precision)))\n",
    "        print(\"Published Precision@{}: {}\".format(n_topk, np.mean(pub_prec_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34f50e20-a934-463a-81b6-4393d36a9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16027192-45ed-4766-b6a1-1d114f23b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_low_freq_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2938e6ae-7a49-45b8-9b11-1af23fd36a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_custom_seq():\n",
    "\n",
    "    n_topk_ind = 20\n",
    "    t_ip = np.zeros((25))\n",
    "    t_ip[0] = int(f_dict[\"DatamashTranspose\"])\n",
    "    t_ip[1] = int(f_dict[\"dropletutils\"])\n",
    "    #t_ip[2] = int(f_dict[\"ip_threshold\"])\n",
    "\n",
    "    last_tool_name = \"dropletutils\"\n",
    "    \n",
    "    t_ip = tf.convert_to_tensor(t_ip, dtype=tf.int64)\n",
    "    prediction, att_weights = tf_loaded_model([t_ip], training=False)\n",
    "    prediction_cwts = tf.math.multiply(c_weights, prediction)\n",
    "\n",
    "    top_k = tf.math.top_k(prediction, k=n_topk_ind, sorted=True)\n",
    "    top_k_wts = tf.math.top_k(prediction_cwts, k=n_topk_ind, sorted=True)\n",
    "\n",
    "    t_ip = t_ip.numpy()\n",
    "    label_pos = np.where(t_ip > 0)[0]\n",
    "\n",
    "    i_names = \",\".join([r_dict[str(item)] for item in t_ip[label_pos]  if item not in [0, \"0\"]])\n",
    "\n",
    "    pred_tools = [r_dict[str(item)] for item in top_k.indices.numpy()[0]  if item not in [0, \"0\"]]\n",
    "    pred_tools_wts = [r_dict[str(item)] for item in top_k_wts.indices.numpy()[0]  if item not in [0, \"0\"]]\n",
    "\n",
    "    c_tools = [r_dict[str(item)] for item in compatible_tools[str(f_dict[last_tool_name])]]\n",
    "\n",
    "    pred_intersection = list(set(pred_tools).intersection(set(c_tools)))\n",
    "    prd_te_prec = len(pred_intersection) / float(n_topk_ind)\n",
    "\n",
    "    print(\"Tool sequence: {}\".format([r_dict[str(item)] for item in t_ip[label_pos]]))\n",
    "    print()\n",
    "    print(\"Compatible true tools: {}, size: {}\".format(c_tools, len(c_tools)))\n",
    "    print()\n",
    "    print(\"Predicted top {} tools: {}\".format(n_topk_ind, pred_tools))\n",
    "    print()\n",
    "    print(\"Predicted precision: {}\".format(prd_te_prec))\n",
    "    print()\n",
    "    print(\"Correctly predicted tools: {}\".format(pred_intersection))\n",
    "    print()\n",
    "    print(\"Predicted top {} tools with weights: {}\".format(n_topk_ind, pred_tools_wts))\n",
    "    print()\n",
    "\n",
    "    generated_attention(att_weights, i_names, f_dict, r_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78ae0ec4-023c-4e86-8f6e-c6b2d29c371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool sequence: ['DatamashTranspose', 'dropletutils']\n",
      "\n",
      "Compatible true tools: ['anndata_import', 'scanpy_read_10x', 'raceid_main', 'seurat', 'Convert characters1', 'seurat_read10x', 'tp_head_tool', 'raceid_filtnormconf', 'scanpy_plot', 'scanpy_cluster_reduce_dimension'], size: 10\n",
      "\n",
      "Predicted top 20 tools: ['scanpy_cluster_reduce_dimension', 'raceid_filtnormconf', 'seurat_read10x', 'tp_head_tool', 'scanpy_plot', 'seurat', 'anndata_import', 'scanpy_read_10x', 'Convert characters1', 'raceid_main', 'tp_cut_tool', 'scanpy_filter_genes', 'tp_easyjoin_tool', 'Cut1', 'wc_gnu', 'mothur_get_lineage', 'coords2clnt.py', 'seurat_find_neighbours', 'newick_display', 'graphlan']\n",
      "\n",
      "Predicted precision: 0.5\n",
      "\n",
      "Correctly predicted tools: ['seurat_read10x', 'scanpy_read_10x', 'seurat', 'scanpy_cluster_reduce_dimension', 'anndata_import', 'tp_head_tool', 'scanpy_plot', 'Convert characters1', 'raceid_filtnormconf', 'raceid_main']\n",
      "\n",
      "Predicted top 20 tools with weights: ['tp_head_tool', 'anndata_import', 'scanpy_plot', 'seurat', 'scanpy_cluster_reduce_dimension', 'raceid_filtnormconf', 'tp_easyjoin_tool', 'scanpy_filter_genes', 'newick_display', 'graphlan', 'fasta2tab', 'bedtools_genomecoveragebed_bedgraph', 'Add_a_column1', 'mothur_tree_shared', 'column_order_header_sort', 'tp_sorted_uniq', 'scanpy_normalise_data', 'tp_grep_tool', 'anndata_manipulate', 'graphlan_annotate']\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_custom_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f496caf-c8e4-4020-8cf9-82497377da20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96355901-8e56-4ff3-a5e8-7e21189d98d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
