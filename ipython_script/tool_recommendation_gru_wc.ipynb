{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool recommendation \n",
    "## (Gated recurrent units neural network with weighted cross-entropy loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import operator\n",
    "\n",
    "import h5py\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as data_file:\n",
    "        data = json.loads(data_file.read())\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_model(model_path):\n",
    "    reverse_dictionary = dict((str(v), k) for k, v in dictionary.items())\n",
    "    model_weights = list()\n",
    "    weight_ctr = 0\n",
    "    cu_wt = list()\n",
    "    for index, item in enumerate(trained_model.keys()):\n",
    "        if \"weight_\" in item:\n",
    "            d_key = \"weight_\" + str(weight_ctr)\n",
    "            weights = trained_model[d_key][()] #trained_model.get(d_key).value\n",
    "            print(weights)\n",
    "            mean = np.mean(weights)\n",
    "            cu_wt.append(mean)\n",
    "            model_weights.append(weights)\n",
    "            weight_ctr += 1\n",
    "    print(\"Overall mean of model weights: %.6f\" % np.mean(cu_wt))\n",
    "    # set the model weights\n",
    "    loaded_model.set_weights(model_weights)\n",
    "    return loaded_model, dictionary, reverse_dictionary\n",
    "\n",
    "\n",
    "def get_predicted_tools(base_tools, predictions, topk):\n",
    "    \"\"\"\n",
    "    Get predicted tools. If predicted tools are less in number, combine them with published tools\n",
    "    \"\"\"\n",
    "    intersection = list(set(predictions).intersection(set(base_tools)))\n",
    "    return intersection[:topk]\n",
    "\n",
    "\n",
    "def sort_by_usage(t_list, class_weights, d_dict):\n",
    "    \"\"\"\n",
    "    Sort predictions by usage/class weights\n",
    "    \"\"\"\n",
    "    tool_dict = dict()\n",
    "    for tool in t_list:\n",
    "        t_id = d_dict[tool]\n",
    "        tool_dict[tool] = class_weights[str(t_id)]\n",
    "    tool_dict = dict(sorted(tool_dict.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    return list(tool_dict.keys()), list(tool_dict.values())\n",
    "\n",
    "\n",
    "def separate_predictions(base_tools, predictions, last_tool_name, weight_values, topk):\n",
    "    \"\"\"\n",
    "    Get predictions from published and normal workflows\n",
    "    \"\"\"\n",
    "    last_base_tools = list()\n",
    "    predictions = predictions * weight_values\n",
    "    prediction_pos = np.argsort(predictions, axis=-1)\n",
    "    topk_prediction_pos = prediction_pos[-topk:]\n",
    "    # get tool ids\n",
    "    pred_tool_ids = [reverse_dictionary[str(tool_pos)] for tool_pos in topk_prediction_pos]\n",
    "    if last_tool_name in base_tools:\n",
    "        last_base_tools = base_tools[last_tool_name]\n",
    "        if type(last_base_tools).__name__ == \"str\":\n",
    "            # get published or compatible tools for the last tool in a sequence of tools\n",
    "            last_base_tools = last_base_tools.split(\",\")\n",
    "    # get predicted tools\n",
    "    p_tools = get_predicted_tools(last_base_tools, pred_tool_ids, topk)\n",
    "    sorted_c_t, sorted_c_v = sort_by_usage(p_tools, class_weights, dictionary)\n",
    "    return sorted_c_t, sorted_c_v\n",
    "\n",
    "\n",
    "def compute_recommendations(model, tool_sequence, labels, dictionary, reverse_dictionary, class_weights, topk=10, max_seq_len=25):\n",
    "    tl_seq = tool_sequence.split(\",\")\n",
    "    tl_seq_ids = [str(dictionary[t]) for t in tl_seq]\n",
    "    last_tool_name = tl_seq[-1]\n",
    "    sample = np.zeros(max_seq_len)\n",
    "    weight_val = list(class_weights.values())\n",
    "    weight_val = np.reshape(weight_val, (len(weight_val),))\n",
    "    for idx, tool_id in enumerate(tl_seq_ids):\n",
    "        sample[idx] = int(tool_id)\n",
    "    sample_reshaped = np.reshape(sample, (1, max_seq_len))\n",
    "    tool_sequence_names = [reverse_dictionary[str(tool_pos)] for tool_pos in tl_seq_ids]\n",
    "    # predict next tools for a test path\n",
    "    prediction = model.predict(sample_reshaped, verbose=0)\n",
    "    nw_dimension = prediction.shape[1]\n",
    "    prediction = np.reshape(prediction, (nw_dimension,))\n",
    "    \n",
    "    half_len = int(nw_dimension / 2)\n",
    "    \n",
    "    pub_t, pub_v = separate_predictions(standard_connections, prediction[:half_len], last_tool_name, weight_val, topk)\n",
    "    # get recommended tools from normal workflows\n",
    "    c_t, c_v = separate_predictions(compatible_tools, prediction[half_len:], last_tool_name, weight_val, topk)\n",
    "    # combine predictions coming from different workflows\n",
    "    # promote recommended tools coming from published workflows\n",
    "    # to the top and then show other recommendations\n",
    "    print()\n",
    "    tool_seq_name = \",\".join(tool_sequence_names)\n",
    "    print(\"Current tool sequence: \")\n",
    "    print()\n",
    "    print(tool_seq_name)\n",
    "    print()\n",
    "    print(\"Overall recommendations: \")\n",
    "    print()\n",
    "    pub_t.extend(c_t)\n",
    "    pub_v.extend(c_v)\n",
    "    # remove duplicates if any\n",
    "    pub_t = list(dict.fromkeys(pub_t))\n",
    "    pub_v = list(dict.fromkeys(pub_v))\n",
    "    print(pub_t)\n",
    "    ids_tools = dict()\n",
    "    for key in pub_t:\n",
    "        ids_tools[key] = dictionary[key]\n",
    "    print()\n",
    "    print(\"Recommended tool ids:\")\n",
    "    print()\n",
    "    for i in ids_tools:\n",
    "        rev_id = dictionary[i]\n",
    "        wt = class_weights[str(rev_id)]\n",
    "        print(i + \"(\" + str(ids_tools[i]) + \")\" + \"(\" + str(wt) + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpack trained model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.5616992e-02 -9.5330365e-03  2.5758710e-02 ...  4.8993718e-02\n",
      "  -2.2291685e-02  3.0981805e-02]\n",
      " [ 3.1450633e-02  2.6231024e-02  1.9229297e-02 ... -2.6189530e-02\n",
      "  -4.6460070e-02  1.7058577e-02]\n",
      " [-6.9594055e-01 -1.3811614e-01 -5.5850995e-01 ... -2.8869215e-01\n",
      "   7.7565575e-01 -2.0640020e-01]\n",
      " ...\n",
      " [-9.5944655e-01 -2.8117830e-01 -6.4869680e-02 ...  5.9618433e-03\n",
      "  -3.1834251e-01  1.6874691e+00]\n",
      " [-7.2706378e-01 -9.6543670e-02 -2.5350434e-01 ...  3.1502196e-01\n",
      "   2.4037234e-01  4.2095359e-02]\n",
      " [-3.4828998e-02  6.8374500e-03 -2.4526609e-02 ...  3.1785283e-02\n",
      "  -5.0432459e-03  5.1588938e-04]]\n",
      "[[ 0.22047408 -0.68096167 -0.24587005 ...  0.24888049 -0.6327199\n",
      "   0.6910393 ]\n",
      " [-0.05191123  0.73034334  0.0808339  ... -0.20938997 -0.33471814\n",
      "   0.07782038]\n",
      " [-0.03099243  0.14367282  0.18357219 ... -0.5525934   0.23153993\n",
      "   0.3233636 ]\n",
      " ...\n",
      " [ 0.58498645 -0.01972618  0.22199841 ...  0.42214638 -0.3336556\n",
      "   0.13377893]\n",
      " [-0.3953597  -0.30302262 -0.10988069 ... -0.5793919   0.66111535\n",
      "  -1.0747936 ]\n",
      " [-0.1501245   0.13915688 -0.46267486 ...  0.18568651  0.07764053\n",
      "   0.09602255]]\n",
      "[[-0.08107597 -1.0688647  -0.6270206  ...  0.45567986  0.18251754\n",
      "   0.44829503]\n",
      " [-0.12612213  0.05344345  0.02121301 ... -0.04413759  0.8056803\n",
      "  -0.47952235]\n",
      " [ 0.6495623   0.05447521  0.15102342 ... -0.70192945 -0.52208763\n",
      "  -1.1659676 ]\n",
      " ...\n",
      " [-1.209864    0.4013653   0.1433393  ...  0.20094326  0.5082645\n",
      "   1.0411558 ]\n",
      " [-0.33832207 -0.13498408  0.33951846 ...  0.5699578   0.0759011\n",
      "   0.01146875]\n",
      " [ 0.14525259  0.38558105  0.16294774 ...  0.38859057  0.27789506\n",
      "   0.360028  ]]\n",
      "[[ 1.0167042  -0.44086325 -0.9856005   0.8861194   0.9543607   0.448733\n",
      "   0.7084744  -0.22128569  0.74147135  0.10396838  0.4662501  -0.85718554\n",
      "  -0.66422933 -0.19653298  0.52782536  0.5135442   0.16526647  0.7622258\n",
      "   0.07518069  0.87702876 -0.07859019 -0.06425683  0.7576806   0.44548625\n",
      "   0.6049861   0.42902943  0.7052371  -0.2793158   1.1170855   0.7934026\n",
      "  -0.18742856  0.11357453  0.17913607 -0.96670175 -0.27327654  0.68042946\n",
      "   0.07060962  0.28479716 -1.140151   -0.22740717 -0.5591563   0.7442778\n",
      "   0.8890057   0.06904715 -0.38563174  0.9370861   0.73960143  0.2346148\n",
      "  -0.27153346  0.2857618   0.21596487  0.38016888 -0.04399906 -0.35109472\n",
      "   0.40821317  0.18425673 -0.11542716  0.8401171  -1.0458958   1.2795936\n",
      "  -0.00202244 -0.41256014  0.09271823  0.0880651   0.7712292   0.9419531\n",
      "  -0.55342644 -0.22834837 -0.14185742 -1.2956159   0.01652186 -0.8760889\n",
      "   0.1334337  -0.7576322   0.686369   -0.35732612  0.8427724  -0.50375605\n",
      "  -0.6128439   1.2127764  -0.510462   -0.54189265 -0.43918425 -0.9611833\n",
      "   0.09708603 -0.23618649  0.04721738  0.1696125  -0.4448708  -0.30557355\n",
      "   0.05350833  0.6941362  -0.09692158  1.1050209   0.5104873   0.3314824\n",
      "  -0.570988    0.06150082  0.6104706  -0.49841103  0.00915328 -0.09133392]\n",
      " [ 1.0167042  -0.44086325 -0.9856005   0.8861194   0.9543607   0.448733\n",
      "   0.7084744  -0.22128569  0.74147135  0.10396838  0.4662501  -0.85718554\n",
      "  -0.66422933 -0.19653298  0.52782536  0.5135442   0.16526647  0.7622258\n",
      "   0.07518069  0.87702876 -0.07859019 -0.06425683  0.7576806   0.44548625\n",
      "   0.6049861   0.42902943  0.7052371  -0.2793158   1.1170855   0.7934026\n",
      "  -0.18742856  0.11357453  0.17913607 -0.96670175 -0.27327654  0.68042946\n",
      "   0.07060962  0.28479716 -1.140151   -0.22740717 -0.5591563   0.7442778\n",
      "   0.8890057   0.06904715 -0.38563174  0.9370861   0.73960143  0.2346148\n",
      "  -0.27153346  0.2857618   0.21596487  0.38016888 -0.04399906 -0.35109472\n",
      "   0.40821317  0.18425673 -0.11542716  0.8401171  -1.0458958   1.2795936\n",
      "  -0.00202244 -0.41256014  0.09271823  0.0880651   0.7712292   0.9419531\n",
      "  -0.55342644 -0.22834837 -0.42492047 -1.3976508   0.00533813 -0.86739045\n",
      "  -0.26368695 -0.64318424  0.41990763 -0.5653222   0.77526665 -0.53102434\n",
      "  -0.3144961   1.2401248  -0.5773033  -0.67542136 -0.99702007 -1.2461667\n",
      "   0.26025447 -0.34932846  0.24324812 -0.15261307 -0.78451496 -0.6236119\n",
      "   0.05585773  0.6731002  -0.09135585  0.77875507  0.6170158  -0.29408118\n",
      "  -0.5774178   0.28834853  0.75008625 -0.82036823 -0.30729493 -0.01262194]]\n",
      "[[-0.37518856 -0.59714156 -0.44934615 ... -0.01825538 -0.84180415\n",
      "   0.19144219]\n",
      " [ 0.09648262 -0.2809093  -0.54070866 ...  0.45090577  0.40503567\n",
      "   0.67566675]\n",
      " [-0.2512132  -0.39510953  0.7539112  ... -0.14859141 -0.24353665\n",
      "   0.09095366]\n",
      " ...\n",
      " [-0.7898523   0.3565713   0.2128103  ...  0.55252457  0.28716242\n",
      "   0.2691986 ]\n",
      " [ 0.4023849  -1.0495026  -0.0115075  ...  0.18893294  0.62758136\n",
      "   0.24154426]\n",
      " [-0.80617285 -0.0270387   0.8453115  ... -0.6424338  -0.01614534\n",
      "  -0.3352279 ]]\n",
      "[[-0.07624876 -1.4621979   0.0729228  ...  1.0047597  -0.20667997\n",
      "   0.8073588 ]\n",
      " [-0.4547249  -0.7404797  -0.58090705 ... -0.47901106  0.19328026\n",
      "  -0.08145288]\n",
      " [ 0.7809303  -0.10710256  0.9396062  ... -0.27554622  0.40042928\n",
      "  -0.36862165]\n",
      " ...\n",
      " [ 0.07621168 -0.5263211   0.04251619 ...  0.2124296  -0.12548788\n",
      "  -0.08006879]\n",
      " [ 0.9038489   0.02391806 -0.8816451  ...  0.36179775 -0.28301936\n",
      "   0.49288496]\n",
      " [-0.40849125 -0.8485953  -0.4792434  ...  0.01884444  0.11210678\n",
      "   0.3034    ]]\n",
      "[[-0.4172137   1.1141695  -0.65156955  0.45261165 -0.49685076  0.02168866\n",
      "   0.2606972   0.7607583  -0.20262049 -0.22759402  0.11726453 -0.05581676\n",
      "   0.6074737   0.218063    0.73154306  0.31282833 -0.12898019  0.41882843\n",
      "  -0.25368664 -0.32256544  0.07274356  0.44250935  0.17581972  0.2731573\n",
      "   0.34820578  0.18604954  0.85613346  0.48964477  0.4241602  -0.72830415\n",
      "  -0.218356    0.1441281   0.820287   -0.03187304  0.29446843  0.5342504\n",
      "  -0.7862998  -0.17479268  0.49635014 -0.6130131   0.30137944 -0.19372335\n",
      "  -0.234208    1.4057627  -0.25002864  0.53119713 -0.03208302 -0.10421062\n",
      "  -0.6510937  -0.4460307  -0.17695366  0.698792   -1.1249089  -0.3875533\n",
      "   0.4736806   0.7249734  -0.2551431   0.13854346 -0.31441098  0.54620665\n",
      "  -1.4849893  -1.1508952  -0.419469    0.63052267  0.7537327  -0.6533188\n",
      "  -0.8356352  -0.06694692 -1.7648989  -1.4830787   0.6656879  -0.49931762\n",
      "  -1.1423271  -0.89572424 -1.0807451  -0.97633934 -1.1573776  -1.4531939\n",
      "  -1.8070276  -1.190584    0.7747573  -1.7018185  -1.0115082  -0.07494794\n",
      "   1.0842971  -0.84419316  0.03299335  0.24826786  0.5234006   0.23074614\n",
      "   0.8332578  -1.4373039   0.44828424 -1.0417454   0.29893622  0.09678093\n",
      "  -0.48878023  0.32470122  1.1037645  -0.24769768 -0.6698144  -0.2874205 ]\n",
      " [-0.4172137   1.1141695  -0.65156955  0.45261165 -0.49685076  0.02168866\n",
      "   0.2606972   0.7607583  -0.20262049 -0.22759402  0.11726453 -0.05581676\n",
      "   0.6074737   0.218063    0.73154306  0.31282833 -0.12898019  0.41882843\n",
      "  -0.25368664 -0.32256544  0.07274356  0.44250935  0.17581972  0.2731573\n",
      "   0.34820578  0.18604954  0.85613346  0.48964477  0.4241602  -0.72830415\n",
      "  -0.218356    0.1441281   0.820287   -0.03187304  0.29446843  0.5342504\n",
      "  -0.7862998  -0.17479268  0.49635014 -0.6130131   0.30137944 -0.19372335\n",
      "  -0.234208    1.4057627  -0.25002864  0.53119713 -0.03208302 -0.10421062\n",
      "  -0.6510937  -0.4460307  -0.17695366  0.698792   -1.1249089  -0.3875533\n",
      "   0.4736806   0.7249734  -0.2551431   0.13854346 -0.31441098  0.54620665\n",
      "  -1.4849893  -1.1508952  -0.419469    0.63052267  0.7537327  -0.6533188\n",
      "  -0.8356352  -0.06694692 -1.4372083  -1.3917946   0.56543916 -0.6169192\n",
      "  -0.9922319  -1.0516937  -1.5468488  -0.6506442  -0.91303444 -1.4278873\n",
      "  -1.3014529  -1.0072238  -0.19696623 -1.3734738  -0.82365096 -0.12238225\n",
      "   0.16701128 -0.27622038  0.4606166   0.64948475  0.63545406  0.09199833\n",
      "   0.58516777 -0.70804787  0.16606098 -1.137155    0.05430347 -0.85437226\n",
      "   0.7870775   0.02518497  1.3186862   0.5681874   0.04870433 -0.30470914]]\n",
      "[[-0.00322205  0.6988598  -0.09159273 ... -0.09473377 -0.16173865\n",
      "   0.06097063]\n",
      " [ 0.06573871  0.5711972   0.07483195 ... -0.17019668  0.15460049\n",
      "   0.14939065]\n",
      " [ 0.06097642 -1.7458929   0.11352207 ... -0.15659007  0.12868284\n",
      "   0.02509537]\n",
      " ...\n",
      " [ 0.15160833  0.2227165  -0.06876692 ...  0.10821529  0.16231163\n",
      "   0.0367212 ]\n",
      " [ 0.02347027 -0.0389801  -0.10177836 ... -0.15465605 -0.0703382\n",
      "   0.06498264]\n",
      " [ 0.14946426  0.5518675   0.02492581 ... -0.12901087 -0.09960859\n",
      "  -0.031876  ]]\n",
      "[ 0.         -3.6083782   0.          0.         -3.5782294   0.\n",
      " -3.5974026   0.         -3.4362102  -3.5958905   0.         -3.6579297\n",
      "  0.          0.          0.          0.          0.         -3.5871747\n",
      "  0.         -3.6038563  -3.5929976  -3.5536711   0.         -3.6782253\n",
      "  0.          0.          0.         -3.5970318   0.         -3.6336784\n",
      " -3.4391768   0.         -3.4894547  -3.6731446   0.          0.\n",
      "  0.          0.         -3.491236    0.          0.         -3.623035\n",
      "  0.         -3.6447568  -3.4796815   0.         -3.6739814   0.\n",
      " -3.5576754  -3.5619004   0.          0.          0.         -3.593622\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -3.6588192   0.          0.          0.\n",
      "  0.          0.          0.          0.          0.         -3.7219968\n",
      "  0.         -3.5504475   0.          0.          0.          0.\n",
      "  0.          0.         -2.054469    0.          0.         -1.1733053\n",
      "  0.         -1.7675289   0.         -1.6447636  -2.0178633   0.\n",
      " -3.5447018   0.          0.          0.          0.          0.\n",
      " -3.55975     0.         -0.5814653  -1.7257402  -3.5472865   0.\n",
      " -1.5045582   0.          0.          0.         -0.8455156   0.\n",
      " -1.4429541  -2.3046117   0.         -0.87567145 -0.93591124  0.\n",
      "  0.          0.          0.         -1.9464508   0.          0.\n",
      " -0.7566515   0.         -3.5199554  -3.5136425   0.         -1.3328067\n",
      "  0.         -3.4983618  -3.4431832   0.          0.          0.\n",
      " -1.776076    0.          0.          0.          0.          0.\n",
      "  0.          0.          0.         -3.5472693   0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -3.708306    0.         -3.5771718   0.          0.          0.\n",
      "  0.          0.        ]\n",
      "Overall mean of model weights: -0.117347\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../data/feb_22/tool_recommendation_model.hdf5\"\n",
    "with h5py.File(model_path, 'r') as trained_model:\n",
    "    model_config = json.loads(trained_model[\"model_config\"][()])\n",
    "    dictionary = json.loads(trained_model[\"data_dictionary\"][()])\n",
    "    class_weights = json.loads(trained_model[\"class_weights\"][()])\n",
    "    standard_connections = json.loads(trained_model[\"standard_connections\"][()])\n",
    "    compatible_tools = json.loads(trained_model[\"compatible_tools\"][()])\n",
    "    loaded_model = model_from_json(model_config)\n",
    "    model, dictionary, reverse_dictionary = create_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembly: \n",
    "# (https://training.galaxyproject.org/training-material/topics/assembly/tutorials/debruijn-graph-assembly/tutorial.html)\n",
    "# spades -> 'bandage_info', 'fasta-stats', 'bandage_image', 'fasta_filter_by_length', 'abricate', 'quast', 'mlst' ... \n",
    "# velveth -> velvetg\n",
    "# (https://training.galaxyproject.org/training-material/topics/assembly/tutorials/unicycler-assembly/tutorial.html)\n",
    "# unicycler -> 'bandage_info', 'glimmer_build-icm', 'glimmer_knowlegde-based', 'bandage_image', 'transdecoder', 'minimap2', 'antismash', 'fasta_filter_by_length' ...\n",
    "\n",
    "\n",
    "## Computational chemistry\n",
    "# ctb_remDuplicates -> ctb_remIons \n",
    "# ctb_remDuplicates,ctb_remIons -> 'ctb_chemfp_mol2fps', 'ctb_compound_convert'\n",
    "# ctb_remDuplicates,ctb_remIons,ctb_chemfp_mol2fps -> 'ctb_chemfp_butina_clustering', 'ctb_simsearch', 'ctb_chemfp_nxn_clustering', 'comp1'\n",
    "# (https://training.galaxyproject.org/training-material/topics/computational-chemistry/tutorials/cheminformatics/tutorial.html)\n",
    "\n",
    "\n",
    "## RAD-seq\n",
    "# (https://training.galaxyproject.org/training-material/topics/ecology/tutorials/ref-based-rad-seq/tutorial.html)\n",
    "# stacks_procrad -> 'bwa', 'bwa_wrapper', 'Grep1', 'stacks_denovomap', 'fastqc', 'fastq_filter'\n",
    "\n",
    "\n",
    "## Epigenetics\n",
    "# (https://training.galaxyproject.org/training-material/topics/epigenetics/tutorials/atac-seq/tutorial.html)\n",
    "# cutadapt,bowtie2 => samtools_flagstat', 'picard_MarkDuplicates', 'picard_AddOrReplaceReadGroups', 'macs2_callpeak','bg_sortmerna', 'multiqc', 'hisat2', 'trim_galore', 'bowtie2' ...\n",
    "# cutadapt,bowtie2,picard_MarkDuplicates -> 'picard_ReorderSam', 'gatk4_mutect2', 'samtools_rmdup'\n",
    "# cutadapt,bowtie2,picard_MarkDuplicates,genrich -> 'pygenomeTracks'\n",
    "#\n",
    "# (https://training.galaxyproject.org/training-material/topics/epigenetics/tutorials/methylation-seq/tutorial.html)\n",
    "# bwameth -> 'samtools_rmdup', 'samtools_sort', 'bam_to_sam', 'pileometh' ..\n",
    "# bwameth,pileometh -> 'deeptools_compute_matrix', 'tp_sed_tool', 'Filter1', 'metilene', 'Remove beginning1', 'wig_to_bigWig'\n",
    "#\n",
    "# bowtie2 -> samtools_flagstat', 'picard_MarkDuplicates', 'picard_AddOrReplaceReadGroups ... \n",
    "# bowtie2,deeptools_multi_bam_summary -> 'deeptools_plot_pca', 'r_correlation_matrix' ...\n",
    "# (https://training.galaxyproject.org/training-material/topics/epigenetics/tutorials/formation_of_super-structures_on_xi/tutorial.html)\n",
    "\n",
    "# bowtie2,hicexplorer_hicbuildmatrix -> 'hicexplorer_hicsummatrices', 'hicexplorer_hicplotviewpoint', 'tp_sed_tool', 'hicexplorer_hiccorrectmatrix', 'hicexplorer_hicmergematrixbins', 'hicexplorer_hicpca' ..\n",
    "# bowtie2,hicexplorer_hicbuildmatrix,hicexplorer_hicmergematrixbins -> 'hicexplorer_hiccorrectmatrix', 'hicexplorer_hicplottads', 'hicexplorer_hicplotmatrix'\n",
    "# (https://training.galaxyproject.org/training-material/topics/epigenetics/tutorials/hicexplorer/tutorial.html)\n",
    "\n",
    "# minfi_read450k -> 'minfi_getbeta'\n",
    "\n",
    "\n",
    "## Genome annotation\n",
    "# (https://training.galaxyproject.org/training-material/topics/genome-annotation/tutorials/annotation-with-maker/tutorial.html)\n",
    "# maker -> 'gffread', 'maker_map_ids', 'jcvi_gff_stats'\n",
    "# (https://training.galaxyproject.org/training-material/topics/genome-annotation/tutorials/annotation-with-prokka/tutorial.html)\n",
    "# prokka -> 'mlst', 'jbrowse', 'taxonomy_krona_chart' ...\n",
    "\n",
    "\n",
    "## Imaging\n",
    "# (https://training.galaxyproject.org/training-material/topics/imaging/tutorials/hela-screen-analysis/tutorial.html)\n",
    "# ip_filter_standard -> 'ip_histogram_equalization', 'ip_threshold', 'ip_count_objects\n",
    "# ip_filter_standard,ip_threshold -> ip_binary_to_labelimage', 'ip_2d_split_binaryimage_by_watershed', 'ip_count_objects', 'ip_convertimage'\n",
    "# ip_filter_standard,ip_threshold,ip_2d_split_binaryimage_by_watershed -> 'ip_2d_filter_segmentation_by_features', 'ip_2d_feature_extraction'\n",
    "\n",
    "\n",
    "## Mass spectrometry\n",
    "# mass_spectrometry_imaging_preprocessing -> 'mass_spectrometry_imaging_combine', 'mass_spectrometry_imaging_preprocessing'\n",
    "# mass_spectrometry_imaging_preprocessing,mass_spectrometry_imaging_combine -> 'maldi_quant_preprocessing', 'mass_spectrometry_imaging_preprocessing', 'mass_spectrometry_imaging_qc' ...\n",
    "# search_gui -> peptide_shaker\n",
    "# search_gui,peptide_shaker -> 'mz_to_sqlite', 'Remove beginning1', 'tp_replace_in_column', 'unipept', proteomics_moff ...\n",
    "\n",
    "\n",
    "## Single cell\n",
    "# raceid_main -> 'seurat','raceid_trajectory'\n",
    "# raceid_main,raceid_trajectory -> 'raceid_inspecttrajectory'\n",
    "# raceid_inspectclusters,__BUILD_LIST__ -> 'picard_MarkDuplicates', 'hisat2', 'stringtie_merge', 'cutadapt', 'tp_cat'\n",
    "# raceid_filtnormconf -> 'raceid_clustering', '__BUILD_LIST__'\n",
    "# raceid_filtnormconf,raceid_clustering -> 'raceid_trajectory', 'raceid_inspectclusters'\n",
    "# scanpy_regress_variable -> scanpy_scale_data \n",
    "# scanpy_regress_variable,scanpy_scale_data -> 'scanpy_run_pca', 'scanpy_find_variable_genes'\n",
    "# scanpy_regress_variable,scanpy_scale_data,scanpy_run_pca -> 'scanpy_compute_graph', 'scanpy_plot', 'scanpy_run_tsne', 'scanpy_plot_embed'\n",
    "\n",
    "# (https://training.galaxyproject.org/training-material/topics/transcriptomics/tutorials/scrna-preprocessing-tenx/tutorial.html)\n",
    "# rna_starsolo -> 'dropletutils', 'multiqc'\n",
    "# rna_starsolo,dropletutils -> 'scanpy_read_10x', 'scanpy_cluster_reduce_dimension', 'seurat_read10x', 'anndata_import', 'scanpy_plot', 'raceid_filtnormconf'\n",
    "\n",
    "\n",
    "## Variant calling\n",
    "# (https://training.galaxyproject.org/training-material/topics/variant-analysis/tutorials/microbial-variants/tutorial.html)\n",
    "# snippy -> 'bedtools_intersectbed', 'vcfvcfintersect', 'Remove beginning1', 'snippy_core', 'qualimap_bamqc', 'freebayes', 'jbrowse', 'vcfcombine'\n",
    "\n",
    "# https://training.galaxyproject.org/training-material/topics/variant-analysis/tutorials/somatic-variants/tutorial.html\n",
    "# trimmomatic,bwa_mem,samtools_rmdup,bamleftalign -> 'samtool_filter2', 'ivar_variants', 'freebayes', 'varscan_somatic', 'deeptools_bam_coverage', 'fastqc', 'ngsutils_bam_filter', 'bamFilter', 'rgPicFixMate', 'samtools_calmd'\n",
    "# trimmomatic,bwa_mem,samtools_rmdup,bamleftalign,varscan_somatic -> 'bcftools_norm', 'gemini_annotate', 'vt_normalize', 'vcffilter2', 'vcfallelicprimitives', 'snpEff'\n",
    "\n",
    "# (https://training.galaxyproject.org/training-material/topics/variant-analysis/tutorials/dip/tutorial.html)\n",
    "# freebayes -> 'vcfallelicprimitives', 'bcftools_norm', 'custom_pro_db', 'vcfvcfintersect'\n",
    "# freebayes,vcfallelicprimitives -> 'vt_normalize', 'snpSift_filter', 'snpSift_annotate', 'snpEff'\n",
    "# freebayes,vcfallelicprimitives,snpEff -> 'gemini_load', 'mimodd_varreport', 'snpSift_extractFields\n",
    "\n",
    "\n",
    "# Transcriptomics\n",
    "#(https://training.galaxyproject.org/training-material/topics/transcriptomics/tutorials/small_ncrna_clustering/tutorial.html)\n",
    "# samtools_sort,blockclust,sort1 -> 'cshl_awk_tool', 'Show beginning1', 'tp_awk_tool', 'blockbuster'\n",
    "\n",
    "# (https://training.galaxyproject.org/training-material/topics/transcriptomics/tutorials/ref-based/tutorial.html)\n",
    "# cutadapt -> 'umi_tools_extract', 'fastq_paired_end_interlacer', 'chira_collapse', 'rna_star',\n",
    "# cutadapt,rna_star -> 'featurecounts', 'multiqc', 'htseq_count', 'rseqc_infer_experiment', 'samtools_stats', 'bamFilter',\n",
    "# cutadapt,rna_star,featurecounts -> 'multiqc', 'deseq2', 'tp_sort_header_tool', 'bamFilter', 'collection_column_join ...\n",
    "\n",
    "\n",
    "# Single-cell HiC\n",
    "# schicexplorer_schicqualitycontrol -> 'schicexplorer_schicnormalize'\n",
    "# schicexplorer_schicnormalize -> 'schicexplorer_schicclustersvl', 'schicexplorer_schicconsensusmatrices', 'schicexplorer_schicplotclusterprofiles'\n",
    "# schicexplorer_schicnormalize,schicexplorer_schicclustersvl -> 'schicexplorer_schicplotclusterprofiles', 'schicexplorer_schicconsensusmatrices'\n",
    "\n",
    "\n",
    "# Animal detection on acoustic recording\n",
    "# vigiechiro_idvalid -> 'vigiechiro_bilanenrichipf', 'vigiechiro_bilanenrichirp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'trimmomatic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Give tools ids in a sequence and see the recommendations. # To know all the tool ids, \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# please print the variable 'reverse_dictionary'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tool_seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrimmomatic\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mcompute_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse_dictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36mcompute_recommendations\u001b[0;34m(model, tool_sequence, labels, dictionary, reverse_dictionary, class_weights, topk, max_seq_len)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_recommendations\u001b[39m(model, tool_sequence, labels, dictionary, reverse_dictionary, class_weights, topk\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_seq_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m):\n\u001b[1;32m     81\u001b[0m     tl_seq \u001b[38;5;241m=\u001b[39m tool_sequence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m     tl_seq_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(dictionary[t]) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tl_seq]\n\u001b[1;32m     83\u001b[0m     last_tool_name \u001b[38;5;241m=\u001b[39m tl_seq[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     84\u001b[0m     sample \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(max_seq_len)\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_recommendations\u001b[39m(model, tool_sequence, labels, dictionary, reverse_dictionary, class_weights, topk\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_seq_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m):\n\u001b[1;32m     81\u001b[0m     tl_seq \u001b[38;5;241m=\u001b[39m tool_sequence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m     tl_seq_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(\u001b[43mdictionary\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tl_seq]\n\u001b[1;32m     83\u001b[0m     last_tool_name \u001b[38;5;241m=\u001b[39m tl_seq[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     84\u001b[0m     sample \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(max_seq_len)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'trimmomatic'"
     ]
    }
   ],
   "source": [
    "topk = 10 # set the maximum number of recommendations\n",
    "# Give tools ids in a sequence and see the recommendations. # To know all the tool ids, \n",
    "# please print the variable 'reverse_dictionary'\n",
    "tool_seq = \"trimmomatic\"\n",
    "compute_recommendations(model, tool_seq, \"\", dictionary, reverse_dictionary, class_weights, topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
